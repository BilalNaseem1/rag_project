{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bilal326/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from dotenv import load_dotenv, dotenv_values\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import anthropic\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import os\n",
        "import together\n",
        "from uuid import uuid4\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import ast\n",
        "import itertools\n",
        "import numpy as np\n",
        "import logging\n",
        "from typing import Any, Dict, List, Mapping, Optional\n",
        "from langchain_community.embeddings import CohereEmbeddings\n",
        "import cohere\n",
        "from pydantic import Extra, Field, root_validator\n",
        "from pymongo import MongoClient\n",
        "import pinecone\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.utils import get_from_dict_or_env\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from anthropic import Anthropic\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "from pprint import pprint\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from tqdm import tqdm\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a_rgCnSD5aK",
        "outputId": "2f22d422-db08-4a25-dc1f-65428d90f570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scrapetube in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from scrapetube) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scrapetube) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scrapetube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VrmP6IudD8me"
      },
      "outputs": [],
      "source": [
        "import scrapetube\n",
        "\n",
        "videos = scrapetube.get_channel(\"UC9aOLLMQht_1FKRxbQe60NA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FuvVn7TbEWq2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Create a list of video IDs\n",
        "video_ids = [video['videoId'] for video in videos]\n",
        "\n",
        "# Create a list of complete URLs\n",
        "urls = ['https://www.youtube.com/watch?v=' + video_id for video_id in video_ids]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'VideoId': video_ids, 'URL': urls})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LLwDlipdEX_Y",
        "outputId": "2bcc79d6-6ca9-4e9d-fe4b-55cdf88b28fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 152,\n  \"fields\": [\n    {\n      \"column\": \"VideoId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"i2K0R9Mfwus\",\n          \"pKMJwPtjFVs\",\n          \"_8DkRO60fvw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=i2K0R9Mfwus\",\n          \"https://www.youtube.com/watch?v=pKMJwPtjFVs\",\n          \"https://www.youtube.com/watch?v=_8DkRO60fvw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f4149c88-3f39-43a3-ba38-5e9e3a7dd6ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VideoId</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YpsB6wNZ5jc</td>\n",
              "      <td>https://www.youtube.com/watch?v=YpsB6wNZ5jc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NgGi4-gykEc</td>\n",
              "      <td>https://www.youtube.com/watch?v=NgGi4-gykEc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WjQHMTASy-4</td>\n",
              "      <td>https://www.youtube.com/watch?v=WjQHMTASy-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iFFfb24_Be0</td>\n",
              "      <td>https://www.youtube.com/watch?v=iFFfb24_Be0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SrZz6WlnUt8</td>\n",
              "      <td>https://www.youtube.com/watch?v=SrZz6WlnUt8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>pKMJwPtjFVs</td>\n",
              "      <td>https://www.youtube.com/watch?v=pKMJwPtjFVs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>xMkndDY8sWQ</td>\n",
              "      <td>https://www.youtube.com/watch?v=xMkndDY8sWQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>yXKKnulowIc</td>\n",
              "      <td>https://www.youtube.com/watch?v=yXKKnulowIc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>R2kpUU0WsQQ</td>\n",
              "      <td>https://www.youtube.com/watch?v=R2kpUU0WsQQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>HURlq6rIEEw</td>\n",
              "      <td>https://www.youtube.com/watch?v=HURlq6rIEEw</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4149c88-3f39-43a3-ba38-5e9e3a7dd6ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4149c88-3f39-43a3-ba38-5e9e3a7dd6ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4149c88-3f39-43a3-ba38-5e9e3a7dd6ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bd35ba4-27c3-4c3d-9d57-b60eef9a4203\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bd35ba4-27c3-4c3d-9d57-b60eef9a4203')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bd35ba4-27c3-4c3d-9d57-b60eef9a4203 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91c65c24-c23e-42cd-a40d-b45204d1a41a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91c65c24-c23e-42cd-a40d-b45204d1a41a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         VideoId                                          URL\n",
              "0    YpsB6wNZ5jc  https://www.youtube.com/watch?v=YpsB6wNZ5jc\n",
              "1    NgGi4-gykEc  https://www.youtube.com/watch?v=NgGi4-gykEc\n",
              "2    WjQHMTASy-4  https://www.youtube.com/watch?v=WjQHMTASy-4\n",
              "3    iFFfb24_Be0  https://www.youtube.com/watch?v=iFFfb24_Be0\n",
              "4    SrZz6WlnUt8  https://www.youtube.com/watch?v=SrZz6WlnUt8\n",
              "..           ...                                          ...\n",
              "147  pKMJwPtjFVs  https://www.youtube.com/watch?v=pKMJwPtjFVs\n",
              "148  xMkndDY8sWQ  https://www.youtube.com/watch?v=xMkndDY8sWQ\n",
              "149  yXKKnulowIc  https://www.youtube.com/watch?v=yXKKnulowIc\n",
              "150  R2kpUU0WsQQ  https://www.youtube.com/watch?v=R2kpUU0WsQQ\n",
              "151  HURlq6rIEEw  https://www.youtube.com/watch?v=HURlq6rIEEw\n",
              "\n",
              "[152 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EqIWrgQWH5g8",
        "outputId": "ae1a32b0-abcc-4d54-89a7-4d2592417eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.7.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.25.8)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.4.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: langchain_anthropic in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.57)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.34.103)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0.20240406)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.0.7)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain_anthropic) (0.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.103 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.34.103)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (0.10.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.103->boto3<2.0.0,>=1.34.0->cohere) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.103->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo langchain anthropic cohere pinecone langchain_anthropic tiktoken youtube-transcript-api pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DdLWhJIwH22X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# from dotenv import load_dotenv, dotenv_values\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import anthropic\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "# from openai import OpenAI\n",
        "# import openai\n",
        "import os\n",
        "# import together\n",
        "from uuid import uuid4\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import ast\n",
        "import itertools\n",
        "import numpy as np\n",
        "import logging\n",
        "from typing import Any, Dict, List, Mapping, Optional\n",
        "from langchain_community.embeddings import CohereEmbeddings\n",
        "import cohere\n",
        "from pydantic import Extra, Field, root_validator\n",
        "from pymongo import MongoClient\n",
        "import pinecone\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.utils import get_from_dict_or_env\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from anthropic import Anthropic\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "from pprint import pprint\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from tqdm import tqdm\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jz6XJOgGoYH",
        "outputId": "ca083acb-a5be-47a5-92f3-7b495516c1cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing videos: 100%|██████████| 152/152 [16:51<00:00,  6.65s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "api_key = \"AIzaSyBTmED2VW3UNps605rxz3bmfoLzoZcepyo\"\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "def extract_summary_and_metadata(video_url):\n",
        "    loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=True)\n",
        "    result = loader.load()\n",
        "\n",
        "    transcript = result[0].page_content\n",
        "\n",
        "    metadata = result[0].metadata\n",
        "    # metadata['source'] = 'https://www.youtube.com/watch?v=' + metadata['source']\n",
        "    metadata['type'] = 'Youtube video'\n",
        "\n",
        "    # Add additional metadata fields\n",
        "    metadata['title'] = metadata['title']\n",
        "    metadata['view_count'] = metadata['view_count']\n",
        "    metadata['publish_date'] = metadata['publish_date']\n",
        "    metadata['length'] = metadata['length']\n",
        "    metadata['author'] = metadata['author']\n",
        "\n",
        "    return transcript, metadata\n",
        "\n",
        "# subset_latest_videos = latest_videos.head(2).copy()\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing videos\"):\n",
        "    video_url = row['URL']\n",
        "\n",
        "    transcript, metadata = extract_summary_and_metadata(video_url)\n",
        "\n",
        "    df.at[index, 'Transcript'] = transcript\n",
        "    # subset_latest_videos.at[index, 'Source'] = metadata['source']\n",
        "\n",
        "    df.at[index, 'Type'] = metadata['type']\n",
        "    df.at[index, 'Title'] = metadata['title']\n",
        "    # subset_latest_videos.at[index, 'View_Count'] = metadata['view_count']\n",
        "    df.at[index, 'Publish_Date'] = metadata['publish_date']\n",
        "    df.at[index, 'Video_Length'] = metadata['length']\n",
        "    df.at[index, 'Author'] = metadata['author']\n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "86-bEEiPIyC7",
        "outputId": "6a860861-0e18-4d88-e000-ed1b09898da7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 152,\n  \"fields\": [\n    {\n      \"column\": \"VideoId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"i2K0R9Mfwus\",\n          \"pKMJwPtjFVs\",\n          \"_8DkRO60fvw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=i2K0R9Mfwus\",\n          \"https://www.youtube.com/watch?v=pKMJwPtjFVs\",\n          \"https://www.youtube.com/watch?v=_8DkRO60fvw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"all right everyone welcome back to another episode of bell curve before we jump in quick disclaimer the views expressed by my co-hosts today are their personal views and they do not represent the views of any organization with which the co-hosts are associated with uh nothing in the episode is construed or relied upon as Financial technical tax legal or other advice you know the deal now let's jump into the episode [Music] hey everyone welcome back to another episode of bell curve we have a very special episode lined up for you today so we're going to be talking to Izzy who is a contributor to Lido doubt and master of validators what an interesting title we're also going to be talking to ashine who is one of the co-founders at opal Network they along with other folks like SSV are pushing forth this idea of DVT which stands for distributed validator validator technology super interesting idea similarly to the haasu episode what we're going to start with is kind of from a high level about why self and solo stakers are so critical to ethereum the credible neutrality and decentralization of the network and then we're going to be talking about how DVT actually works in practice how it enables more solo and self-staking and what that could potentially look like in the future we got a very interesting timeline from him so stay tuned for that uh I thought the staking router I'm going to shout out Izzy here I thought he gave one of the most intricate detailed descriptions of how the staking router is going to work in practice that I've heard anywhere else and we really got into the nitty-gritty of what some of these modules might look like and the idea of an internal fee Market within that staking router which I found fascinating all that to say I'm going to do a super clickbaity thing and tell you you got to stick around to the end of this episode we talked about the potential of a restaking module within the staking router and that was I'm still sort of thinking about the the consequences of that part of the discussion so definitely make sure you stick around for that all right guys that's enough for me talking into your ears here let's get on to the show all right everyone welcome back to another episode of bell curve I'm joined as always by my Fearless co-host miles O'Neal today we are lucky to be joined by ocean who is the co-founder at opal and today I'm also joined by Izzy who's a contributor to the Dow and master of validators at the lighter down so guys welcome to the show thanks for having us um super excited about this guys and really want to get into I think the the meat of this podcast we're going to be focused on you know we've been very focused this this uh so far this season on this idea of decentralization as offense and want to specifically dig into this concept of DVT and how that's going to integrate with the staking router but before I think we even get into into that nitty-gritty it would make sense to start a little bit at a higher level and I'd like to just ask the open question to the both of you you know solo staking is something that's seen I think as being very critically important to ethereum and the decentralization of the network and just kind of a high level question I'd love to get a State of the Union as it as it is on the state of solo staking how important is it what are some of the design decisions that ethereum is making so just want to communicate to listeners like what is the state of solo staking today and how are we encouraging that moving forward yeah I can have a go at that I think um the state is solo staking at the moment is in a pretty good place or at least in my perspective it's starting to like turn up the words and start to like kind of see in a lot of growth I think over the two plus years that the beacon chain has been running at the very beginning it was you know very solo stake dominated there was lots of you know True Believers that were in early from Genesis and then over the kind of the course of a year to a lot of the growth and staking has been more in the like big product life staking the liquid staking protocols particularly when there was no withdrawals and stuff it was kind of more like safe to lean towards a liquid representation of steak and but now that we have the merge behind us and distributed validators are starting to grow we're starting to see lots of liquid staking protocols in particular really double down on getting more and more solo stickers involved and um that's probably where I see things at the moment is There's A Renewed interest in getting more Solace takers involved and getting a lot more for client diversity in there than we currently are at so I maybe want to like toss it over to Izzy and see how he sees it from largest perspective but I'm relatively optimistic at the moment I think it's busy this has been any number of years yeah I think actually makes makes a good point that we kind of started off with um all of like the the protocol diehards are like the people that really believed in this effort um who had also had the technical Acumen uh and that's kind of like the Genesis validator set which consisted uh majorly of solo stickers um and then we kind of saw a transition you know like as as proof of work ethereum and proofers they get here and we're running in parallel where let's say larger organizations or at least more professional staking organizations started to get um their their presence on the network largely because of like the technical Acumen and so it's much easier to start for example validating on a new network if you already know more or less how to validate whereas for solo stickers it's kind of like a natural ceiling of how many people are technically able and willing to take a certain amount of like technical risk involved and with regards to running validators and also um putting that much ethereum at sake and I think there's like a couple of events that have happened since the Genesis of the beacon chain back in in December of 2020 that have really made it a lot easier for solo stickers to participate so um two of those are obviously two of the large ethereum upgrades that have happened so the merge itself and also the introduction of withdrawals that have like meaningfully reduced the technical barriers and risk surface area that solo stickers would need to kind of like be wary of um there are also like more minor upgrades throughout about this so for example like we started with Oxo withdrawal credentials so like the so-called BLS withdrawal keys and now validators are spun up with ox01 smart contract withdrawal credentials that are a lot easier to reason about um and a lot easier to to secure and things like that so I think that has also made solo sticking easier and then of course we've seen a lot of maturity in terms of like the tooling and client software that exists around running validators um arguably in the beginning uh decline diversity wasn't so great because there was obviously a few clients that were more mature than others but since then we've seen not only new clients um enter the space but also like the the really really amazing Evolution and growth of a lot of the other clients so there's at least four or five clients that are almost at parity I would say both in terms of features and in terms of how easy they are to use but we also have tooling that rests on top of or to the side of these of these clients you know it might be like Docker installations that you can use or front ends that allow you to kind of like set up your value later however you want to set it up with things like avato or dab node so all of these kinds of things coming together are culminating in what I would say is kind of like a reintroduction of of a new set of solo stickers to the protocol so people that have been learning about ethereum and proof of stake over the last two and a half years but also now that have much more tooling and knowledge at their disposal to be able to like be feel safe enough and competent enough to to dip their toes in so we see that liquid staking Protocols are taking protocols in general are also meeting this kind of like renewed demand for solo participation which I think is vital to a network like ethereum um by adding new ways for people to participate yeah I think that's really well said and you see I think you touched on a critical component which is just reducing the complexity overall for solo stickers and maybe we can get into almost a setup of what a solo sticker requires today but I would love to also get a sense of you know sriram who miles and I are going to talk to on the next episode who's obviously the the founder at eigenlayer talks about Market forces actually you might have daps in the future that want and will actually pay a premium for Block space that's more decentralized and perhaps run by solo stakers I think the idea here being that you know what I'm trying to get at a little bit is sort of the core reason why ethereum wants solo stickers which I'd always thought of as you want this to be a robust Network both and robust in in some senses mean it's geographically distributed and it's not easily shut down you know against some sort of government intervention I mean how do you guys think about the the sort of need overall for ethereum to be decentralized in the key role of solo stickers is that about right or are there other components that I'm missing there so maybe I can take a first stab at this and ocean can follow up um there was actually a recent podcast that Justin Drake was on where he had a take on this that was perhaps a little bit spicy yeah that was good yeah so he basically said like the two most important things for um or I mean paraphrasing or at least the way that I understood it just so to make sure that he doesn't get mad at me um like the two most important things for like a truly decentralized um and robust like blockchain are censorship resistance and credible neutrality um and decentralization is basically the most Surefire way to get those things right but it's not absolutely necessary if you somehow find a way to get those in another way um to a certain extent I think that's true but I think um the fact that decentralization is so important and like baked into the ethos of a lot of these kind of initiatives and and projects that we're we're doing right to kind of like Revitalize Financial infrastructure means that decentralization always needs to um exist at least in the form of the common person being able to participate in the network um as a buffer against credible neutrality or censorship resistance at some point being capturable or attackable um you kind of always need this uh security mechanism if you want to call it that or like perhaps in the parlance of like American constitutionalism like a Second Amendment right for for like a militia of people that are always going to be there to um uphold the values of of this kind of like digital sovereign and I think it also really ties into this idea of uh what we're trying to do uh with crypto right um the idea that everybody can participate by helping disintermediate power and the best way to do that is by having as many people involved as possible um I know that that might sound a little bit contradictory coming from somebody that you know participates in the Lido dial but what we're trying to do um so like actually Mike I think this might have been a conversation that we're having a couple of weeks ago but there's this kind of like this idea like there is in Jurassic Park you know where there's this quote that life finds a way like money finds a way um so what all of these systems are trying to do um is ensure that there's like Risk Management and principled ways to let's say curb the most pernicious effects of the financialization of things while empowering people to participate in these ecosystems to secure these ecosystems um and to have like a voice and power uh in everybody's Collective future and so I think to that extent that's why solo staking is is vitally important and why networks like ethereum that have to a large extent um bar some like hiccups let's say or technical design decisions that have been built around the idea that anybody should be able to run a node and that many many people should run a node uh is why they're so successful and have so much cultural mind share within uh blockchain ecosystems is he you just reminded me that I even secured your permission I love that quote so much money finds a way that that was going to be the title of this season and then I just forgot so I'm glad we at least worked it into this episode because I like that idea so much of money finding a way and I wanted to start this conversation by just you did a great job uh just highlighting why solo staking is so important and I think one of the big the big hiccups to that are roadblocks if you will is just many there's a limited number of people who are competent out there to run the the sort of Hardware requirements and that's where I want to segue into DBT which is short for distributed validator technology if you hadn't heard about that before my guess is that you're going to continue to hear about that quite a bit in the coming months and years and Sheen you and Colin it at opal and other platforms like SSV have been pioneering this idea so can you kind of just give us the broad Strokes of what distributed validator technology is and like how it actually accomplishes that problem of uh or that that solution of encouraging more solo staking yes happy to so distributed validators are the idea of running an ethereum or any other type of blockchain validator validator on more than one machine instead of them just being like one single server what's nice about this is you can then introduce fault tolerance where if you know one of your machine goes down you'll still be online and this is something we don't have in the web 3 and proof of stake space as of yet to my knowledge the vast majority of proof of stake chains your validator is you know one private key that signs messages and you know different chains punishes downtime you know more and less severely but ethereum is one that will punish you if you're down for even kind of six minutes um so what distributed validators do most validators most servers machines die all of the time you know don't expect your server to stay on and not need an update and you know never need touching for years at a time um and if you're a solo sticker you're basically on call 24 7 365 and you know if you want to have up time like the professionals you need to have redundant Hardware usually ready to go if a drive dies or you want to be on call being able to be you know woken up in the middle of the night and if you go offline none of these are you know super scalable for a one-man solo operator or something like it so when you have distributed validators and you're now working in group groups um if your node goes offline no big deal the other three will keep it up and keep it on this is useful you know just generally for having better up time the example I can give is I've been running as a solo Staker and as partly as an Enterprise validator since Genesis the Enterprise nodes I've deployed of 99.9 uptime you know for the last two plus years whereas the solo node is at about 97 because you know machines die and I'm not always around but with TVs the goal is that you can get you know up towards three nines and more of uptime and you know a group of home stakers should be as effective as you know your professional load operators and that's kind of what TVs aim to achieve and it's the goal is that you know solo staking you know your models never go down so long as if a group of people working with you or Squad staking is often being kind of picked up with the aiming for it yeah I think that's kind of short description of distributed validators that's really excellent I I want to actually get a little bit more in the weeds with you here and one of the one of the questions that I think Miles and I want to drive drive towards here is just exactly not even in the the current state but the future state of how low could we get the hardware requirements implementing something like DVT I mean is there a future here where uh solo stickers could be running some of this stuff basically on their their cell phone but before we get there I actually want to just make this a little bit more concrete for what Opel the protocol looks like and I know there are sort of four main components here so you know you've kind of got the DBT Launchpad and user interface you've got a new custom middleware client uh called car on I believe I'm pronouncing that correctly opal managers and then Obel Obel test net so could you kind of just walk us through the you know the core components of the protocol and if I missed anything yeah I just want to give uh listeners a little bit more of a concrete sense of what this is going to look like in practice yeah absolutely so I'll start up at the high level with the user interface or what we call the distributed validator launch pad so this came out of a problem where you know you want to work with other counter parties but you know you need to trust them or at least you need to you know figure out what you're going to do together you're going to make a proposal um you know what are we going to validate how many keys are we going to validate on what chain you know is this going to like point at a certain particular withdrawal address is it you know in Lido or otherwise um so we originally kind of did all of this on the command line you'd kind of prepare this look at like long bytes of strings and stuff but it's really difficult to kind of be confident that you're setting up what you expect to set up with you know other counterparties if you're just looking at kind of output on a terminal so we developed the distributed validator Launchpad which is a spiritual successor to the ethereum Launchpad that was you know put in place by um the ethereum foundation consensus and others at Genesis and the idea behind it is it's meant to be user interface to walk you through the process of setting up a distributed validator and um to use it you log on one person makes the proposal so they might say that hey you know Mike miles Izzy and myself we're all going to run a distributed validator together I paid in I put in all of your ethereum addresses I say we're going to make you know 10 validators and it's going to be on mainnet and we're going to send them all to this you know no so safe address and then I send you all the link you guys can eyeball it you can you know click view on each scan you make sure I'm not trying to send this to my ledger or trying to kind of bait and switch you guys with you know what we're supposed to be setting up and once everyone is kind of approved and signed off that they like are happy with the terms and conditions you then move over to the command line and into Caron which is the like software client um Caron um is a middleware it sits in between your consensus client and your validator so it more or less is just an extra piece of software that you put on your node kind of like how Mev Mev boost you can add-in and one of the jobs it does is it will facilitate the key creation for your validator meaning um what's special about a distributed validator is there is in the happy path or the way we encourage people to use it is there's no one human with access to the private key instead the four of us would all come together we'd run a bit of software and it would spit out I call it four one-thirds of a private key it's not quite exactly how it works but everyone like each of us have a piece of the private key and we need three of us to you know put together the full private key um that even you know day one has you in a much safer place and when it comes to getting compromised or if someone like stealing your private key and getting you slashed um and at this point yeah you're now looking at like you have a deposit data you want to activate that validator maybe this validators you know working as part of a liquid staking protocol maybe it's not maybe it's just a custom one and the open manager smart contracts I alluded to these are splitter contracts for the most part we have a few different varieties in the The Works that we're hoping to kind of show more of the world soon enough but this is the idea of you know do we guys want to split this 25 percent each way are we all contributing different amounts maybe we don't want an equal split maybe we're doing this on behalf of somebody else so that somebody else gets 90 and we're splitting 10. and that's kind of where the manager contracts come into play and then the test Nets is tooling related to letting people run this and you know ensure that this is going to work for them get them to kind of learn how to mine DVS and work with one another so that they can do this in production so that's kind of uh well I will say that this is a tour of kind of where we're at currently with our you know obal as a protocol one of the things that we didn't mention here more broadly is in the kind of earlier versions of distributed validators you need to trust your counterparties you need to kind of work together if miles goes offline you have to kind of hit them up on telegram be like hey man your node's offline can you go sort that out please yeah if you leave it offline there's nothing a whole lot we can do to kind of Force anything to change and but in the future we're working on uh succinct proofs of who is online and who was offline and that eventually it's like okay if miles is off for a week he gets penalized and we get all the rewards so we're not as upset if he's offline but that to do that in an ungameable manner that you know you can't kind of cheat is quite difficult so that's why we kind of refer to that as our distributed validator protocol or kind of our future version where we get this you know it's all in cryptography there's no human kind of social air consensus going on I think that's a great overview of kind of where we're at today and you know and I think about the barriers to I guess making uh self-staking more more prevalent I think about one the hardware requirements um to the actual Capital requirements right and you've already made great progress in bringing that down from 32e and then three just maybe the natural incentives for for folks that are not you know naturally passionate about this technology and and decentralization of the network um but just starting with those first two you know if I could ask you to look forward into the future a few years um I'm very curious to get like a sense of how low we could get the hardware requirements and as well as the capital requirements you know it's just something that one day we could run on our phone like like the Solana phone um or some version of that or or you know if I have one eth at some point will I be able to you know maybe mint an LST from from the staking router so I would love to ask you to project forward a few years and and 100 I don't even think it's a few years more likely um so the first one of running on a phone I think you make a great point there this is something that distributed validators I think is you know very beneficial for there's been lots of people that have worked on you know building clients to run on very low resource Hardware but you know you don't want to cut it too fine you might say or like at the very extremes particularly with mobile you know your internet is connecting disconnecting you're not going to be on 24 7 365. so we think running low powered validator nodes is much more suited to like running a distributed validator than to run you know something like full solo and particularly if you're a solo Staker trying to run this all yourself you're like I want fault tolerance but I you know don't really want to run some give it to someone else it's like cool I run on and you know my house my friend's house my phone and you know some other thing and that's kind of how you kind of have lots of fault tolerance and then on the capital requirement side I think that is also something that can be mitigated by distributed validators because you don't have to have the same amount of bond if somebody isn't like you know God mode over this validator and have total control if they're just kind of you know one piece and you assume that even if they were offline malicious you know worst case scenario they're you know not harming the validator too broadly so long as there's not a few of them that are offline it really reduced the risk profile of actually bringing them in and delegating some other stake and I maybe want to throw it over to Izzy on that regards because collateral requirements for staking is a kind of a a big you know testy subject when it comes to like delegated staking and should validators be collateralized you know lighter famously is not but they have you know plans both for collateralization and also for how solo stickers can get involved with and without collateralization um so they want to see how he thinks about TV reason its impact on hardware and collateral yeah absolutely so maybe even going back to like one of the original questions which is um what is the presence of you know solo stickers on the network right now what does that mean for the network what are the barriers for first for solos taking existing um because that ties into like the whole question around bonding requirements so uh apart from like the technical complexity and and the operational complexity um which is much reduced and also the technical like surface risk um which is also much reduced due to the the recent ethereum upgrades um we contend with the issue of like Financial approachability of of the Enterprise of running of elevator right so obviously if you were solos taking um you needed to not only have uh 32 each in order to be able to run the validator but you needed to have it like in the beginning um so it's really hard to like borrow it and then run a validator um and so what a lot of liquids taking protocols basically did was allowed people um to participate in the grander let's say uh Collective Enterprise and not in the sense of a business sense but like a community effort of um securing the ethereum network without necessarily having the that minimum 32 each obviously distributed validators like like oval is working on or even like SSV is working on allows users to do this by putting their money together so like you split the 32 each into multiple smaller pieces of a deposit depending on how many people participate in the cluster and then therefore you can have like Collective participation of one full node via more participants as opposed to you know one person needing all of that capital and then you also have like permissionless liquid staking models um like rocket pool which also has been very very successful in terms of adding net new node operators to the network and I think this should be lauded for that where basically you had a capital a collateral or Bond requirement where a node operator or at least a capital allocator associated with this node operator puts up a certain amount of money and then the remainder let's say of the balance on that validator can be can come in from inject injection sorry from injection from stickers so normal people who would participate in in lsts in general when we started with and by we I mean like in in ethereum seeking as a whole uh with permissionless bonded validators this bonding requirement had to be very very high right um rocket pool started with 16 Eve and now we've seen that liquid staking particles have started to reduce this bonding requirement based on a number of different factors so one is obviously the maturation of protocols themselves but also the underlying Network layer the second thing is that there are upgrades in the works that will potentially make it so that if a node operator like disappears or is unrespondent or like loses access to their validator keys for some reason um the network will be able to issue a command that is validator via the execution layer which means that liquid seeking protocols can do this via Smart contracts to eject these validators right and so we call this like triggerable exits and this isn't an EIP that will help fully calm sometime next year a couple of hard Forks perhaps after after dencoon or maybe even they meet at hard work after dencoon um and there are so so let that in concert with a lot of other things for example that historically we actually haven't seen that many slashings and slashings um it's very very difficult for them to ramp up to the amount of like slashing a full 16 not a full 16 but up to 60 needs on a validator has basically LED protocols to do like a risk adjusted uh implementation of what is the sizing that Bond should be so obviously like the main thing that reducing bonds means is that you lower the barriers to entry for interested participants right um it also means that there's a corollary that the people that have already put up the bonds can basically just multiply the amount of validators that they have using the existing Capital by Rolling It Forward um but that's also not necessarily negative providing that these people are actually you know like independent node operators and smaller organizations and distributed validators adds like an even more kind of like interesting aspect to this um if we get to a point where risk analysis for example after we have eip7002 which is the triggerable exits uh functionality that we were discussing allows you to exit validators and this happens let's say within a year and everybody collectively believes that this will happen within a year you can say that on a worst case scenario if a liquid sticking protocol were to launch with a very small amount of bond um like let's say for eth or less and that this upgrade happens within a year realistically speaking like it's very unlikely that such a large amount of node operators will go offline um that that amount of money or loss that the cost of the protocol will be so so substantial as to not take that risk to lower bond that much and DVS allow you to lower it even more so if you say that you have four if bond for another for a validator um you could split it across four participants for example like in a three or four model like ocean was saying or you can split it even more into like a five or seven model but you can maybe even say that due to the fact that it's so much more difficult to get three four people let's say or three people because that's the consensus threshold to align on doing something nefarious we we lower it even more because this idea of you know like multi-party agreement needing for for something to happen it's a lot easier to make people agree for things that are like mutually beneficial and a lot more difficult for them to agree on something that's like malicious or nefarious um so that even unlocks another potential in in further reducing bonds and further increasing let's say the breadth of economic actors I.E solar stickers that will would be able to from a financial perspective and interested participate I think that's that's a great overview um and you can see the direction we're going here but I think I've kind of one more question before we move on to the staking router and that is like once we get these barriers as as low as possible both on the hardware the capital um then it becomes a question of you know how do you like productize or package this in a way that it with a value prop that resonates with you know a larger population of users maybe Beyond this kind of crypto native um and and very passionate folks about ethereum right it's and I'm just kind of thinking out loud here but you know is there ways that you could make an app better if you are running a DB you know on your phone or something app something else like that or is you know it we've talked a lot about the principal agents problems associated with you know lsts you could argue that you know you mitigate a lot of these problems by minting your own lsts you know as as part of a permissionless set and so yeah just curious to hear you know early thoughts on like how you plan to to Really frame this value prop to it to a larger set of users yeah I think I'll start with that one and maybe the first thing I would say is that the value prop to different Staker entities is quite different not everyone kind of sees the same you know pros and cons in DVS and we've talked a lot about the solo stake here so for those guys it's you know high up time for my own note if I'm so lucky that I have a full validator or a route into the liquid staking pools if they don't have you know the ether the collateral to either have a follow-on or to have you know the bond for some of the other protocols so that's kind of the the solo stakers um benefit the benefit to the liquid staking protocols I'll touch on maybe lightly maybe as you can expand on but for those like protocols it's about de-risking you know the stake that they give to their operators right now they have to have like they're making of you know a big amount taking a huge amount of trust in like the operator that they like allocate you know millions of dollars of stake to and there's currently forces them to pick the like reputable big brand name you know Noah going nowhere type of node operator but they'd much rather push the kind of extremes that and go down the kind of to the more solo sticker but it's kind of hard to take that risk if they have total control and then the one we haven't talked about is maybe the more centralized operator which you know does exist in this non-trivial part of the like stake in ethereum for these people distributed validators is more on the cost side and the other operational side is what they really gain um having cheap software-based fault tolerance um really can impact their operations particularly in how they've deployed a lot of decentralized providers because there's no safe way to run a backup have not moved towards more bare metal or on-premise machines and instead kind of stay closer to the cloud side because of the machine dies in the cloud you can kind of press a few commands and detach the the disk or the private keys and be like cool I'm like back in charge of that private key whereas if it's on like a real machine and a real server somewhere and that thing dies you can't talk to it you can't get to it you need to like plug it out at the wall and so most of them haven't gone that way um but with distributed validators they can you know move to more on-prem they can kind of come out of the cloud they can keep all of their keys with separate people they don't have you know one human that has kind of the keys to the kingdom and even when they're like upgrading versions they don't have to take their software offline and they can you know do general maintenance the one I always talk about is you're not you know pinging your devops in the middle of the night to be like hey even how did you need to get it within an hour for our SLA it's like oh we've lost one fix in the morning okay we've lost two hit the alarm get out of bed but for the most part yeah they can save Hardware they can save risk and they can save operational expenses with TVs um and that's you know generally the case with mostly others as well but yeah there's no one benefit for everyone I guess each each kind of type have the different kind of pro and Contour there's a really interesting point you brought up um to the end in terms of like we're gonna have to seriously reconsider like what kind of alerts wake us up in the morning um because if we're running a fleet of distributed validators and our alerts are still like uh you know the validator is has been down for 15-20 minutes that's like catastrophic it's not it means like there's at least two people out of four you know that are that aren't doing their job or three people out of seven or something like that um so are we gonna really need to change how we do our monitoring and alerting but on the other hand it also means that we'll have to wake up a lot less than we do right now yeah that's the hope yeah nice that's a good goal as a lover of sleep I I Am pro that idea so I I wanna I wanna transition here into talking a little bit and just sort of set the stage for why we're talking about self-staking and DV technology within the context of the staking router and Lido and one key theme of the the season I think hasu Put It Best in the last episode is this idea of decentralization as offense especially for protocols like widow or other liquid staking providers because lydo does something that's so core and close to the metal of ethereum that in order for it to continue to grow its market share and continue offering great services to folks that want a stake we want to make sure that it's as decentralized as possible and there are two key ideas I think we really want to dig into the staking router a little bit here but I also want to Izzy just poke at you for sort of a high level on Dual governance between Lido and and Steve as well hey everyone we've got a great episode here but before we do I just wanted to give a quick shout out to permissionless this is the biggest and best conference in all of defy it's the one that we do with bankless who's a great partner for us last year we had almost 7 000 people there in West Palm Beach we are moving this year to Austin Texas from September 11th through the 13th and if you are a listener of bell curve any of these last five seasons this conference is basically custom made for you we're going to be talking about liquid staking the theme of this season we've got a bunch of great panels on Mev if you listen to the app chain thesis we've got a bunch of Cosmos folks out there in full force we're talking about the converging architecture of Solana the roll-up space in eth and Cosmos so I would love to see all of you there and to reward you for being such great listeners to bell curve you get a special 30 off code it's bell curve 30 that'll get you 30 off tickets click the link in the show notes and then head over to the permissionless site and make sure that you get your ticket today again that is bell curve 30 click the link in the show notes but let's get into the nitty-gritty of the staking router and you know for context this actually went live so Lido V2 is you know the exact date but I think it went live a couple months ago and that introduced withdrawals and Design idea of the staking router and I actually before we even get into what that is and how that you know we've been sort of teasing the how that applies to DBT and having different modules I actually want to get a sense of how things worked before so we get a sense of what the original state for something like Lido was and then how the staking router is going to be a massive Improvement there and I've actually got for you here if you bear with me while I share my screen a helpful diagram that maybe we can walk through and for folks who aren't listening I can try to describe a little bit about what this is but it's a it's a diagram of some of the core processes of of Lido and so easy if you wouldn't mind just sort of walking us through this diagram so we could understand how it used to work within Lido and then we can go through the shift that that has taken place with the introduction of the staking router and just explain what that is sure um so oh let me try to read through this diagram now uh basically the original version of the lighter one ethereum protocol uh was what we call now the curated operator Set uh it consists of a node operator registry that is made up of a list of curated IE permissioned by the Lido dial meaning that they were proposed of the Dow and the dial ratifies the acceptance of these node operators joining uh as uh users basically they can use the protocol but on the validator side um and this node operator registry creates or the participants in the registry rather create validators um undeposited too so just the validator keys themselves and and the deposit slips they submit these to a Don chain software the the protocol through the node operator registry and this creates a buffer let's say of validators that are waiting for deposits when a user goes to the lighter smart contracts either via a friend and like Cloud identify or just by interacting with the contract directly they submit if to the Lido on ethereum Smart contract and this eth goes to a buffer basically and whenever there is enough if in the buffer for it to constitute a certain increment let's say of a whole number of validators I.E like if you have eighties and you can't fund a validator with that you wait until there's multiples of 32. it gets deposited to the deposit contract on the execution layer side meaning like the ethereum 2.0 uh as it used to be called uh deposit contract where all of the stake teeth goes and actually it's this is really interesting like accounting uh thing with ethereum where all of the state data is just sitting there on a contract on the execution layer um and basically gets uh deposited at the same time or mapped to a certain validator key um that has been input into this this buffer ahead of time uh by node operation or operator registry so there is a staking allocation mechanism that happens uh behind the scenes on chain like none of this is off chain whereby the node operator with the least amount of currently active Keys is always prioritized for news sake what this means is that operators that joined the protocol earlier so for example like when the protocol started uh back in December of 2020 or January 21 um if if say that they're all running a thousand each validators each right now and there's a new cohort of node operators that join the new node operators get all of the new eth provided that they have submitted validators to the buffer until they catch up with the previous cohort and then it's like a round robin fashion um this was a design decision that was purposely made to basically distribute um stake if as fairly as possible across the entire node operator set so we find ourselves uh now you know on the 13th of July 2023 like two and a half years later uh the node operators uh the curator registry basically consists of 29 operators right now technically it's 30 but the two merged in a business or fiscal sense sometime after they joined as node operators and so the protocol treats them as one um and there is a really really good distribution of stake across the set so no one node operator has vastly more amounts of stake um being operated through them as a result of you know like Lido State def demand then then other node operators and unless they've specifically for example chosen not to add more valid letters and there might be business decisions behind that are scaling decisions bad and that and Etc um and just one thing to note is that so after if it was submitted to the lighter contract and before it actually gets deposited um there's two kinds of like uh off-chain things that that happen one is a deposit security module um and the oracles these are off-chain mechanisms that end up having on-chain impact uh so the deposit security module is basically the bot that determines when to uh deposit new if to these validators it looks at a couple things like what's the current gas price so you know if gas is in the hundreds maybe it won't do deposits until the gas goes down a bit and it also double checks the Integrity let's say and the correctness of the data that has been submitted by node operators so that's something incorrect isn't done and the oracles are responsible for reading obviously the balances of validators on the beacon chain and this is how the whole rebase mechanism for for sdeath Works um but from a uh staking perspective they're also responsible for making sure that the contract has updated information with regards to like how many validators each node operator is running in terms of how many are active so this was this was V1 and the the kind of like large Improvement that I would say that happened here as there was which is one of the two main components of uh Lido V2 which was the upgrade to the light on theorem protocol I think on the 15th of May so one was obviously adding the support for withdrawals and the second one was the framework um for the functionality of the staking router so the sticking router itself is kind of like an architectural decision about how the lighter protocol should work it took what was previously happening in lighter V1 which is this curate node operator registry and it encapsulated it into the first of eventually I hope many modules um that might be built by lidocontributors might be built by Third parties it might be built by some um conjunction of the two or or collaboration of the two and basically transforms um Lido from like a very very specific thing into a thing that allows you to create plugins that attach to the main set of of light or smart contracts and then therefore allows Lido to work more like a Marketplace of stake allocation rather than like a very specific thing so when a user goes and eventually let's say deposits eth into into Lido uh as it is right now the staking router will make allocation decisions for which modules the stake um should go to it'll do this at least in its first iteration once there are new modules right now there's only one module it's the current uh curated operator registry um it'll do it in a very similar fashion to how it it allocates stake between node operators within a module so let's say that there's a new module that's created tomorrow this module is running using distributed valid bidders and allows solo stickers to participate this module will have a total maximum allocation threshold which is in terms of the total amount of stake that flows within the lighter protocol so let's say one percent of stake within Lido this threshold will be configurable and manageable by the Dow itself and so if the new module is created tomorrow and it has uh zero percent of Total light or stake in it and its maximum threshold is one percent all of the new stake that goes to uh that gets added to Lido basically will flow to this new module in this until it reaches that one percent once it reaches that one percent the curated Operator Operator registry which is like the Mainstay module will act as like like a a bucket and pick up any additional stake until the Dow either adds new modules or decides to change what the maximum threshold um for the second module is and this process will repeat as more modules are added and um can even change it depending on um sorry if you add modules that work slightly differently but maybe we can get to that a bit later so the main change is that V2 brings the staking router and the staking router is a framework for designing validator sets that can attach to the lighter protocol so instead of saying we will have one Vault that works this way one Vault that works with permissioned uh node operators that do not postpon so one mod one Vault that works with non-permissioned operators uh with a strict Bond model we create the staking router which allows you to design your own vaults and then these vaults can be attached to the lighter protocol based on the Dow decision so the Dow would need to do like a security assessment a risk assessment and probably some sort of like smart contract audit to figure out if it's safe it would then assess the economics and the tokenomics of these proposed modules and then once they're added it can manage what the stake allocation to these modules is that's is a super helpful question or explanation there and we're going to get into a whole bunch of different questions there one other way I think it was helpful for me to think about this and if you're a little bit more financially minded or comfortable looking at a balance sheet we're actually looking at a very high level illustrative sort of version of a balance sheet of Steve both before and after the staking router gets implemented this shout out to Adrian from Steakhouse Financial this comes from a blog post that he wrote but it sort of shows you this this idea of the you know the assets and liabilities of Steve you know pre-staking router you see that it's the asset is all this this one big green block which is State either in the curated validator set or the whitelisted validator set that that lighter used to have the liabilities are Steve because that can be withdrawn and then there's a surplus which I guess is kind of like the Insurance Fund or maybe the treasury or something like that but there's some Surplus in the case of a slashing event or something like that now we've sort of seen a transition you know in Lido V2 as actually happened and with the the staking router instead of the the assets of steath being one big green block you can see there'll be multiple different blocks of different types of validator sets so you could have professional node operators maybe that's the the whitelisted set that we have today but I actually want to the first question that I that I have for you guys is like if you had to take a a poke or a guess at some of the modules that we could expect right one is is DBT and this is finally how we're going to connect right this idea of the staking router and DVT because that feels like an obvious module there also could be I know in the um the blog post on hackmd that light out what they suggest there could be a community uh set as well dowels feel like another obvious fit uh perhaps uh even like in a more institutional set of validators something like that so I'd love to you know Izzy I I know this is all you know very new and you know there's probably some stuff that you might not be able to mention as your position as master of validators but like could you kind of give us a sense in of of the diversity of what some of these modules might actually end up looking like in practice yeah that's that's a really great question so and like all of this is still to a certain extent up in the air because uh the way that it'll work from a governance perspective is that there basically needs to be a module design presented to the Dao uh it'll kind of look like a like a technical architecture design record probably with a company uh technical specs and maybe even like a business case and then the Dow decides whether these modules get get added or not but the the really kind of like important and the linchpin here is that although the diagram we're looking at kind of separates like you said like the assets column into different node operator classes so professionals small groups Dallas solo stickers and things like that modules themselves get are more like like channels for node operators as opposed to segments of node operators like what do I mean by that so if for example um there are modules that use distributed validator infrastructure and I think there will be like a lot within the next 12 to the um 18 months and buy a lot like I mean three to four which is quite a lot if you consider that one module right now houses uh all of this like hundreds of thousands of stickies um operators that are both professionals or solo stickers or like dials that want to run validators as a community will be able to participate in these modules potentially or the module might say that actually this is a module purpose purposefully built for like you said like high class energy integrate uh level operators that all operate using like saktus and ISO certifications and are fully insured and stuff like that so the modules will be able to come up with like different um design decisions for which node operators can participate in those modules and how and that's also something that's really really important for third parties that might be looking to build uh the modules because they can either add like their own um kind of like spin on them or they might want to integrate them into like other networks somehow or you know empower the users or the operators in some other ways but it also allows for like this cross-pollination of operators between the different sets so you might have an operator uh just like any professional node operator that is in the current curated operator set and then they might also 101 distributed valve there's another module that's going to be possible and the staking router will basically be responsible for making kind of like this risk adjusted allocation between these different modules I think that's a key point there um that I'd like to double click on and that you know you could see participants of the curated also participating in the DVT and maybe more solo Staker sets um and I just want to get it kind of like the the benefits of that and I think about you know the risks uh for the speech holders of you know opening up the the validator set to solo stakers is that you know you take on more risk that you you know could your teeth could be slashed right because you have less institutional operators of these notes um but is there a way to de-risk this expansion by perhaps like clustering a you know a a node operator like chorus one with a bunch of you know solo stakers and that way is you know as long as the institutional you know uh node node operator is is running then it can kind of protect I guess the other DV you know solo stickers in a cluster that's that's a really really great question um and so there's a very large segue here obviously to the kind of stuff that ocean is working on in a noble so I'll let him take that part but um I hope the professional node operators don't go and pretend that they're solo stickers I'll get very mad if they do and like I'll know uh because it's my job to know but um the idea is that yes you should be able to use different combinations of of different operator types or classes to minimize either the risk that a certain cluster and the validators that they run poses to the protocol or the impact of something going wrong right and you can choose to either minimize both or one or the other and then find different ways to do that and it's up to the designs of each module to figure out how to do that and it can range from anything from like bonding requirements um that might be very basic and linear if you're talking about like a completely permissionless solo module because that's the safest way to make something like that work to more exotic things where if it's like semi-permissioned or you have operators that are not necessarily by seeing themselves but prove that their their identity to the extent that it's provable that they're not also another operator right not necessarily like it's Joe in his basement in Montana but that it's not um you know chorus one or something like that and come up with like exotic non-linear bonding requirements or maybe say that if you can prove that you provide on-chain insurance for all of the validators that you're on then you don't need a bond but that the insurance is available or like and I this is why we're talking about DVS you cluster them together in DV clusters of different kinds of makeups and I'll let ushin talk about that and because all of those can offer different like technically risk adjusted ways to approach this problem yeah so I'll pick up their um starting with the challenge of the totally permissionless one and the bonded one and as easy alluded to it's like it's very hard to figure out if someone is actually two people and they're not actually just civil attacking your network so if you're trying to you know only let Max one operator into the solo class you don't want them like you know getting 10 applications in you can do things like bonds but as you said you you end up looking at like the data you're trying to do statistical analysis be like they regularly have outages the same times these other people they might be related but it's very hard to kind of prove you have to kind of get quite subjective about it um so the idea of starting with totally permissionless we don't know who you are so long as you put up a bond it's probably fine it's definitely going to work that's you know a bit on the like more extreme end and we've been you know working with the Lido team on and off for more than a year I think at this point and like kind of getting towards that like Direction and one of the things we've looked at is what you've alluded to of mixing solo stakers with the professional node operator set and I think we can talk about this but just over the last few months we've finished up some testing with about 40 um node operators and maybe about 12 of them being from the professional like curated set the other 30 or so being mostly solo stickers and we put them into groups with half curated half you know solo stickers and the nice thing about doing half and half is if you need two-thirds of them to agree to anything you have quite a lot of comfort that you know at least some of the curated side agreed to it or you know the curated side also don't have total control anymore they need at least some you know solo stickers to get involved and agree to things so that when we talk about you know some of the earlier modules when you kind of go from you know we want DVS but maybe we're not you know putting this totally like putting an algorithm totally in charge it's let's have one with a mixture of curated non-created we'll give them a certain amount of allocation let's see how that does and then you go fully solo Staker and then you go fully solo Staker and it's bonded and permissionless and we don't know anything about you and you can kind of work your way out that kind of decentralization I think that's that's really interesting and I I also want to kind of poke at some of the the different sorts of um I guess the flexibility you have within each of these modules um and I think about you know also on the fee level you know something like a a protocol like like maker which is very closely intertigned with with Lido and a big distribution channel for Lido you know could you see something you know like a a like a REV share right that is done through customized fees or something like a kickback for um for maybe protocols that are power users or other distribution channels that that also you know want control of their own module and they also want to see some of the economics of you know the Steep that they are bringing in um to the to the overall you know validator setting yeah that's that's definitely one of the things that uh was purposefully kind of included in the broad nature of the way that the modules are designed so even like the the total fee itself uh you know like the Top Line fee which is 10 isn't set in stone technically although practically um personally at least I think it makes sense it's neither too high nor too low um and I don't think it makes sense messing with that right now in the immediate future but down the road um as protocol economics change and obviously or hopefully I guess and this is not a financial advice but the value of if also probably changes um the the 10 fee like might make sense to change it to something else but within that um the share itself between what goes to the Dow if any what goes to node operators and what goes to potential third parties that are also included in terms of making sure that this module runs well or like you said is that is a distribution Channel um there's a lot of different ways to approach this and it can range from for example them getting a percentage of that that that fee split um all the way to something like secondary collateral right so the there's a lot of permissionless staking protocols that uh I don't know if they offer the option but so most right now like require a secondary collateral to eat um I did in my personal opinion I think like eth um or at least the staking token itself like the LST uh SD Ethan in lighter's case is like the prime collateral um and probably shouldn't be substituted for something like this but from a complementary perspective it might make sense uh in certain cases for certain modules um to add collateral and for example node operators that post collateral in the secondary token might be eligible for something like uh increased reward share or you know it's it's akin to like staking that that token whether it's a utility token or a governance token or something like that and allowing module designers and creators to play with those kinds of like Financial uh aspects I think a allows the modules to kind of be seen as like business cases on their own so that we can find sustainable models for how do you create validator sets but eventually and this is um to the point that you brought up that hustle mentioned in the previous cast the idea of developing a fee Market uh for uh validator sets and but I think fee is perhaps like constrained but like one more General market so you can say that this module offers this this and this and that might be you know like fully kyc uh operators or um operators that run all of their validators like in in green data centers that are not the cloud or something like that and then eventually either the protocol um or users themselves although technically right now it is the protocol because for the moment we believe that like an opinionated proxy for for user decisions here ends up working a little bit better like if you look at delegated proof of stake in general it ends up very top heavy so we're trying to ameliorate some of those um kind of Side Effects by Distributing stake in as Equitable a manner and in terms of like prioritizing certain things for robustness like you mentioned earlier miles like geographic distribution um jurisdictional diversity and and obviously like software and infrastructure variants as well um and and eventually if you allow these like modules to compete against each other but perhaps within certain like bounds or limits so that you don't drive uh fees or or rates or rewards rate as like the most important thing because then you will end up with um like Corner cutting and stuff like that I think we'll be able to find that the design space for creating your own modules allows like more sustainable mechanisms to to be created is he either it's I have a couple questions for you on that which is that that idea that also introduces sort of a local fee market for Lido similar to how ethereum has I think a very elegant fee Market frankly is very interesting to me I want to get a sense of you know what are the market forces that are going to shape fee markets within Lido and what is governance ultimately going to be responsible for because I kind of see these two conflicting forces here where there's sort of a free market rate between people who want uh access to a specific set of validators and this could be sort of the SRI Ram idea of maybe there's a premium on the Block space or more decentralized validator sets using DVT like opal or SSV but then on the other hand um I could also see governance right trying to have its own I'm trying to get a sense of what is going to be determined by the free market right versus what does Lido governance going to be responsible for so can you give me like a sense of how you see that playing out yeah to a certain extent the free market is going to determine that and I.E that is lighter governance because like anybody can go buy ldo and have a hand in uh or have a say rather in in determining that outcome there is no um decision on this obviously because like the Dow hasn't voted on it right I think at least for my personal opinion what's happening right now is that there's an exploratory phase um we're trying we being like the current set of contributors that are working on this we're trying to determine what ends up with the right balance of sustainability um and robustness but at the same time also being like appeasing to uh Capital efficiency right you don't want to go too much in One Direction uh where you sacrifice Capital efficiency to the extent that like you have you have ceilings on uh the total amount of like Supply that you can you can meet because that demand will end up going elsewhere um and that those other parties might not have the same considerations or principles that you do um and on the other hand you also don't want to go too much in the other direction and make everything about competing on price so I think the the protocol's job here at least from my perspective and like this is this is what I believe in espouse is that it needs to set up the right let's say risk-adjusted safeguards for what a sustainable validator set looks like in the future and that hinges upon like the things that we talked about in terms of like what makes a decentralized validator set and how do you maintain credible neutrality uh and and censorship resistance in the network and if the Dow eventually um sells on a protocol where users can choose specifically like which validators there their state goes to it needs a balancing mechanism to prevent that like let's say possible lopsided decision making from affecting the overall protocol so if you make it so that like anybody can choose where their state goes to as opposed to like how it is right now it needs to be able to countermand the additional risk for doing that so if at some point somebody comes with like gazillions of dollars right and says I only want the stake to go to this one node operator that might put the rest of the like protocols like fungible tokens at risk so the protocol itself should have safeguards um that rebalance the stake in a way that makes that as difficult as possible to happen I think that makes sense and it it touches on a theme that we've been talking about you know first that decentralization is offense um with liquid sticking protocols but also governance minimization is offense um and it it I think you're touching on a tricky balance there because if you really were to let you know put this decision in the hands of the user or maybe you know put this decision on the supply side where you'd say like these modules bid what the lowest possible fee that they would take right to to for the to get the deposits to win the deposits Natural Market forces just move this towards you know most of that stake going to the largest operators um and so yeah I guess is it fair to say that you know while there's some you know whether it's Meb with PBS you can build that into the protocol and and basically you know ossify it completely the uh and the parts of the even the Lido contracts you will be able to ossify at some point but is it fair to say that maybe the you know monitoring the allocation of deposits is something that will you know never be able to be completely you know basically ossified or or left to the free market or the user choices yeah I mean never is a big word um I think that that eventually there so there's research being done on this end it's it's public so like I'm not saying anything secret um we've like a specific set of contributors have been working on this with another mind research team we discuss it with node operators like almost every day and with uh other parties in the ecosystem like like obol um and even with with other staking protocols right the the difficulty here is trying to come up with um a semi-autonomous mechanism right like you don't want to keep touching this and you don't want to like having to grease the wheels like every every couple months uh that runs well enough um and that at the same time is not like let's say exploitable under uh bad weather scenarios and the latter part is what's really really difficult especially with permissionless systems so uh stuff like DV is is amazing and at some point if distributed validators end up being as battle tested as we hope and we think that they will be it wouldn't be surprising to me if most validators are run uh in a distributed fashion but you can't just say because that validator is distributed that I'm contending with uh end parties now instead of one right like four or three um the permissionless nature of of what we're trying to build eventually means that it's very possible that these four parties may be one um and that will be very very difficult for a protocol at least from a purely automated on-chain perspective to discern that they are it is one and not four or three or two um and so to a certain extent I think there may be uh kind of like bumper guards that you have in like a bowling alley that might need to you know write the the ball every now and then um but the question is making sure that those are put far enough away that they only have to come into play very very um seldomly and not in a way that in danger of the protocol and one of the key ways of doing that um and we're kind of going back to the question that you mentioned earlier is like this idea of dual governance so dual governance is all about how do you address like this principal agent problem where the the protocol that is basically responsible for making certain decisions May or not make or is governed by actors that may or not have may not have exactly the same interests or at some point diverging interests um with the the holders of the liquid staking token so for example in this specific case like LD holders versus Steve holders so the the idea of dual governance is a allowing for sde folders to have a veto in the case that these incentives meaningfully diverge but also a way to let's say like meter the the possible like worst case scenarios that can happen in a protocol right so it's not only important for people to be able to to veto if something bad might happen or something that don't agree with might happen but also to delay whatever needs to happen long enough so that the people don't agree with it can exit gracefully versus you know leading to a kind of situation where everybody's running for the exits even if they might not need to that it ends up having like unintended consequences down the line because we're we're talking about D5 year right there's no accounting for how people use uh the tokens that are theirs in a completely permissionless system and so you you want to create systems that um make make it clear that like if if something bad might happen uh or something that they don't agree with they have adequate recourse basically to to say goodbye and do so in a way that doesn't put anything at risk yeah we could go down this this whole Rabbit Hole of dual governance I I have a couple couple more questions for you on sort of the ossification of the protocol and I want to actually lead into a a a restaking question because we're going to have SRI RAM on next week but one one metaphor that has been um been miles and I've been playing around with a lot this this season is is uh actually like the App Store and if you look at the development of the app store right it actually kind of started out as this one thing that wanted to be a little bit more permissionless uh but ultimately what Apple decided one is they wanted to give their users a better experience and they started having like higher barriers to entry and requirements for developers because the ultimate sort of Market factor or Market uh determinant for them was wanting to provide a good experience and Izzy that's the question that I want to ask you and open it up to ashine as well is just try to get a sense of like how permissionless can we get here because at a certain point if we just let anyone become a validator right if the if the staking router was to become so permissionless that that anyone could kind of do anything then you could risk some adverse consequence for let's say steveholders right if you had irresponsible validators who risk getting slashed and then you know the way that the pool is currently structured everyone would sort of get punished for that so that's my sort of question for you is how permissionless can we ultimately get here and where does the line sort of exist so ultimately uh and we're talking about like I don't know four to six year Horizon from now I think we can get my permission list until then there's a lot of work that needs to be done um some of the core problems to contend with in the space are obviously like like civil attacks which we mentioned earlier um the idea of like how do you fight these when they happen or at least minimize their impact when they do because that's the most likely scenario that that they'll happen and then you just want to make sure that the protocol is robust enough to withstand them um when they do and um the the second aspect is and and this kind of goes through the whole idea of building like on-chain identity and not in the kyc sense but in the sense that like anybody can participate to the extent that we can make sure that they're not also somebody else so there's a lot of data that you you would need to bring either from on chain or like a side the chain on chain so um for example like we talk about things that happen on chain right but the gossip Network itself itself is not on chain um so validators are not like aware of the physical location of of other machines that they're talking to those things to a certain extent will always need some sort of like proxy for like meet space um and right now that proxy uh is governance eventually when there are are mechanisms to bring enough of that data on chain so that um these protocols can reason about it in a sufficient manner it doesn't need to be foolproof but it does need to You Know cover like 90 of cases um then we will be able to reach systems that are like either semi-autonomous or almost fully autonomous with very very few safeguards or let's say configuration parameters being tuned by something less like a governance mechanism I would say and more like caretakers got it um in oh sorry machine well the one thing I was going to add to that which is I think permissionless is quite achievable but I think the one that I'm more skeptical of is Market forces driving like Risk parameters and stuff and being like Oh yeah we can just look at you know redemptions and we can look at people's like what they want and assume that there's kind of some natural place like put risk and stuff I think what a lot of times is very hard to appreciate is how Black Swan staking is in that like when something bad happens it'll be you know non-linearly worse than anything that's come before there's not going to be some data of oh yeah you know they started to decline in performance so automatically we reduce their like Risk and their tolerance it's probably going to be everything was fine until it was unbelievably not fine um so you can still do permissionless but I don't think there'll be like a market price of like finding a clearing price that is the price of risk or at least not not an accurate one I think yeah I using that's such a good point and one one maybe this is uh you know we can end on this and it'll be a lead into our our next interview is the possibility of a big theme that we're exploring the season is sort of the intersection in between something like liquid staking and restaking and frankly the first thing that sort of comes to mind that is at the same time very interesting but I could honestly being very problematic is something like a restaking module within the staking router on Lido and I just have a lot of questions about how that would mechanically work for instance if the middleware that um that you know we stickers end up running get tokens that are denominated and not if I mean how would frankly something even like that work but then also the bigger question of you can imagine right now it's the bear market and everyone's being very you know frankly rational and you know concerned with things like safety but we know that doesn't happen in Bull markets as well and you can imagine this negative reinforcing cycle in between let's say a Lido clone and an eigenlayer clone that aren't as responsible and acting in it's good faith where they just layer up on a whole bunch of different risks that they end up taking they drag the you know the weighted apy up and people end up going into uh you know sort of much less safe conditions so maybe if we could take both of those at each time I would love to get your sense of if a restaking module would be possible and how would that work if the tokens were you know if the rewards were denominated in something other than Ethan then maybe we could talk about that that last point I think the thing I'd like to hear from Izzy is how a liquid staking token might stay fungible while people want to start doing different things like I know I was listening to the hospital podcast yesterday and he was like very insistent there will only be one derivative it'll be like uniform and everyone's going to use it but how does that work if there is you know demand for different modules and some people want the kind of risk averse when some people want the restaking one how yeah how do you blend risk profiles I guess so there's a bunch of different schools of thought on this and I would say that there is no consensus uh right now um my the way that I approach this is that if you want things like that it's better to build them on top of sdeath rather than to build them alongside estef and like eigenlayer basically does this already right well it allows you to take your sde for your RF and deposit into a contract um not much is happening to it yet but you know eventually the idea is that that it will so to a certain extent the exposure that St Eve at least exogenously might have to something like restaking is unbounded um however it's probably going to be more appealing if there is some sort of core level um integration let's say be between the two right it might give you better apy it might give you more granular control over the validators which you need in order to have like a good feedback loop over liens of collateral otherwise you know things might get like really really out of hand if you go really high up the restaking stack um and that in itself might take the form of a staking router module and then you basically at least in in the current way that sticking router works rely on the Dow to put like appropriate risk safeguards around that right so one is the thresholds to uh regarding how much stake might be allocated to that module and two is what the expectations would be for that specific module with regards to um like Risk mitigation or risk management options so it might say that like for every validator that is spun up in this module x amount of whatever you wanna whatever you want to denominate that in it might be in SCE rewards it might be an eth or it might be in um these kind of like secondary tokens that end up being accrued like you said Mike uh gets sent towards like paying for insurance for these validators something like that um and so I think that also is the most reasonable way to address the other question that you have is uh sorry that you had ushing which is how do you not mess with fungibility like fungibility for me is the most important thing um for St Eve uh fungibility and liquidity and they kind of go hand in hand so if you eventually add modules that either allow you to take more risk than other modules do or for example like specifically stake with specific operators or in order to you know have a certain certain qualities of validators I think they end up doing the same thing which is that it can it can if not managed properly like end up creating like different classes of overall risk which if they get too big Contra the rest of the stake um could threaten like the entire protocol at the protocol's job and governance's job is to a not let that happen so you have to put the appropriate safeguards in place um from a metering perspective and from a configuration perspective and then you also have to make sure that the actual business logic Within These modules appropriately meters the the possible negative effects of something going wrong so it might even be something like these need to be fully insured or they need to post collateral or um it's opt-in but only a certain amount of stake can opt into this and if you don't get in you don't get in so like there's a lot of kind of like accusations you know that are made in terms of oh if the staking protocol is too big like you know they're going to mess with like Brock block proposal slots and then construct Mev blocks um vertically and all of this stuff and I I've actually never seen any proposal in Lido for for this to happen like either on governance or uh amongst like other people that I've talked to so like there's a lot of things that can happen uh there's a lot of things that could happen it could have happened in terms of like attacks of ethereum in the past uh but you ended up with them like not materializing because of let's say like the culture and and the quality of people that are associated with this network like on average and at large so if we make sure that the culture and the ethos is there to not engage in like the most like de-gen let's say um kind of practices and inducing rewards but follow a path of like reasonable sustainability but at the same time balancing for Capital efficiency um I think that there's there's a path forward there that doesn't end up endangering uh The Wider protocol Izzy let me just uh I I want to make sure I'm not focusing on this too much and I also just for the audience I want to highlight you know this idea of being fungible so the reason why this is so important eigenlayer actually addresses this in their in their white paper where they explicitly say that we have no plans to issue a token because positions in eigenlayer you're going to be running different types of middleware with different risks and return profiles associated with so there's not you know you can't make it it's not fungible like it is with Steve and Heath uh that said there actually is a precedent in finance for creating liquid fungible positions for Less fungible like actually Bond ETFs would be a really good example of that so we do know that that does there is at least some pretty large precedent actually in Chad 5 for it and the question that I that I have for you is I've pulled up here again Adrian's sort of uh Steve assets and liabilities their balance sheet and if this was a bank looking over at the right instead of on the assets part of their balance sheet instead of you know professional node operators small group Style it would be treasuries would be a group of assets that you'd have commercial real estate would be a group of assets that you have small business loans whatever it is they'd sort of divide up their their different assets and um you know Steve would be replaced by deposits the the mechanism you know my understanding of the mechanism for how Lido pays out to pays out its rewards is there's an oracle it checks the balance of eth that's in the the total validator Set uh and then Steve gets minted and Steve uh will act like that it gets rebased to to Holders but then it also gets um you know new Steve shares you know which essentially act as claims on the pool get minted to the both the treasury and node operators so my question just from a mechanical standpoint and what the pool of assets would look like is if you had these uh validators that were opting into additional hardware and receiving rewards in Oracle would check that and then but you still wouldn't be capable of minting anything other than Steve so ultimately the balance the the pool right of different things would Encompass other tokens in there right and you would still just get paid out with Steve and suddenly Steve would represent a claim on not just Ethan a pool but mostly eth plus some other tokens or would you shift the way that the you see what I'm saying is is I understand the question so there's no there's no answer to this um got it in terms of like there's nothing that has been said and so these are obviously like things that we're thinking about um my intuition here is that so so first of all the callout that you're making is correct in the current curator operator uh registry node operators uh are paid daily basically or receive their their rewards fees daily and it is pro rata based on how many validators they run as a total number of uh compared to the total number of validators run by the protocol so node operators do not make more or less based on their like their daily performance um however with staking router this can be determined at the module level so if some modules want to pay operators that are performing better more than they than they pay operators that don't perform as well they can but it's up to the module to figure out the logic there now that logic might require um certain upgrades to like the main Oracle or it might work with like a satellite Oracle it's up to the module to figure out how to do that on a grander scale like when we're talking about you know this this four to six years down the line there are a lot of different things that I think need to need to be considered in terms of like in how you were talking about like the that the total risk of like a balance sheet which might be treasuries or Commodities or something like that and it's only not it's not only about like um rewards adjusted returns but also in terms of what is the contribution to the robustness of the protocol of all of these different modules so a solo staking module which might make a little bit less less money in terms of rewards rate than like a module run by uh fully professional Seekers although with things like DVS like that might not even be the case anymore might contribute more to the robustness of the protocol than you know the the equivalent amount of validators run by professionals would be so to a certain extent the protocol should value that higher then no on a per validator basis than something that's from the curated operator registry and these kinds of like you can call it risk adjusted calculations right but it's really about the sustainability of the protocol are going to be core in terms of figuring out what what the right allocations are so when we talk about risk restaking the same kind of logic applies there if the rewards that these validators are getting um might be denoted in something other than Eve there's like a couple ways to approach it one is that they actually um don't relate to the minting of sdeath at all and it ignores those rewards and they are represented in another way so it might be another token or it might be something that you can claim um by holding sdes uh but not actually rebased in the full value of the token right so you can like assume that their value is zero in terms of like what's the contraposition um on the on the liability side for the protocol or you can do other things like instantly sell them for if and then therefore and restake it and then then that works um I think different modules will take different approaches to this and then we'll figure that out so that's the other cool thing about like the module-based approach maybe you don't sell them for eth maybe you sell them for a token of a project that wants to do this and then that's a that is a way for like that that token to a cruise on value got it uh fascinating questions to ponder and thanks for I know a lot of this stuff is frankly it's still being written and discussed but it's just it's always interesting to consider and we'll have to poke a little bit about at uh SRI Ram next next episode uh is he in machine guys you've been so generous with your time thank you so much this is given miles and I a ton to think about if folks wanna find out more about you or follow you or or either reach out maybe you're seeing from a you know or interested in uh you know validating or machine or uh easy sorry what if I know more about Lido I think folks know better pretty well what's the best way to follow you yeah I'll start there so I think you can find us on Twitter at Obel Network and the website is allball.tech o b o l dot Tech and yeah the thing I would encourage people to do particularly if they are a homesteaker or someone considering staking is to give a try in the launch pad try and run something on girly you know set up a squad with your friends give it a try because it sounds like lighter might have some opening for node operators in the foreseeable future yeah actually there's an opening for some node operators right now uh today's actually the the last day for for people who are interested to apply uh for the wave 5 onboarding so this is for the curated operator module you can find uh more information about that on the Lido Forum so research.light identify um there's already over 100 applications so uh our team is going to be insanely busy once we get back from Etc uh we will be at ECC there will be a Lido Booth uh if you're in Paris come find us uh I'll try to make sure that uh I get you some merch if you say that I'd listen to you on the bell curve um you can find us of course on Twitter at Lido Finance uh and myself at isdrsp uh that's my name um and in general there's like this is a really really exciting time for me um all of the stuff that I've been thinking about for the last couple years in terms of how do we create sustainable validator sets is is like the culmination of that is the staking router in the first couple of modules that are being developed I'm super excited to be exploring the the solution space here with teams like uh oboe um and others and I think the next uh 12 to 18 months are really really going to be pivotal in terms of showing not only how important it is to build systems that allow for like inclusivity um but also the idea that if you create like design spaces for something um you encourage other people to help you find Solutions as opposed to try and come up with with everything on your own like honestly both lighter VT and and especially like what opal is doing uh by creating middleware and and not necessarily like a prescriptive way to do things is examples of the same thing guys this was uh just such a great episode thank you so much I Myles and I keep saying we got to make these shorter but how you know what could we have cut out here this is just such great conversation so uh we really appreciate both your time and uh yeah I'll have to do it again soon all right miles what a great episode that was I knew we were biting off quite a bit with DVT plus staking router and and we didn't even get to dual governance which is no I think again the mark of a good episode uh we're being very ambitious with the the planning sheets for for each one of these shows but man there's just so much to dig into there I thought that was one of my my favorite episodes of yeah couldn't agree more and you know came out of it extremely excited about you know the potential of the staking router um and and have a very good idea of how this intersects with you know DVT and and the importance of solo staking and how you know Lido is really trying to align itself with what is beneficial for ethereum the protocol um so yeah yeah it's kickoff from there so you know starting off with solo staking DBT DBT is not something that I have necessarily heard of that much even six nine months ago I feel like incredible increasingly very smart people are working on solving this problem whether that's oboe or SSV or or whoever and one I think part of the reason we didn't really talk about this why uh Solo or self-stakers are so important is if you look at the scaling architecture of Roll-Ups and l2s I sort of have this kind of pet thesis that these Roll-Ups are going to be using a centralized sequencer for a long time if not indefinitely at the very least it's a much thornier problem right than than folks initially gave it credit for so I think the importance of a very credibly neutral or decentralized base layer at ethereum is probably even more important today than it has been in the past so Technologies and mechanisms and creating a sort of incentive base for solo staking through DBT I just I just want to underscore how important that is in the current Zeitgeist and moment yeah that's a great point I didn't actually think about it from the sense of you know the the makeup of these Roll-Ups is is reinforcing the importance of having a good chunk of the validators that be these independent solo stakers that you know can are very hard to censor from any sort of yeah you know government or another organization yeah and it was encouraging in talking to ashine I think the the part of that conversation that stood out to me you know I won't go back and talk about the the mechanism for how it works today but when we asked him about tomorrow and timeline and I think the question that you and I were really interested in driving towards here was what is the timeline for reducing the hardware requirements here to something where you could imagine you know being a solo validator or using just your cell phone and he said it might not even take years so that that to me was a very impressive or a very interesting kind of takeaway got me excited no 100 because you know I think the current requirements associated with this even once you lower the capital requirements from 32 each to you know say four eth um there's still kind of a ceiling of in terms of the amount of people in the world that are one you know motivated to run a DV validator have you know the technical chops to do so um and I think lowering those barriers uh is extremely important to actually opening this up to a broader population and yeah I was I was surprised I was thinking it would be you know in the order of five years before we could get something like this to just run on your phone in the background right um or or just even have like very very flexible options here um and then once you you know lower these hardware and capital requirements as as much as you possibly can it just becomes a question of okay how do you you know frame running a DV validator in a way that that is attractive to folks who you know may not have been interested in staking in the beginning or may not be crypto native um and you know I think there's still some open questions there but at the very least this addresses all of the problems of you know for folks that um are already interested in staking and and interested you know in pushing forward the decentralization of the network yeah I agree with that and we talked about segwaying into the staking router I mean even before that we've talked a lot about alignment and the closer you are to core protocol of our that sort of base layer infrastructure of ethereum more aligned you want to be with ethereum so I think it makes a lot of sense for not only Lido but the rocket pool is probably the you know the most extreme example of this being extremely aligned with sentiment of ethereum there's actually a interest I'm not sure if you've got there was a there was a vote I think in rocket pool governance as to whether or not to self-limit is very similar to the light of vote that happened in May of last year very different answer that it was kind of an overwhelming consensus that we should self-limit the caveat that I will say there is that you know in the immortal words of 50 Cent it's hard to hard to hate it from outside the club you can't even get in you know it's very different uh saying you're going to self-limit with you know seven percent of stake versus 30 or something like that so but it is just it's indicative of this alignment sort of issue and I think Lido's doing my sense is that light is a team of True Believers in a lot of this stuff but I want to get into the the discussion that we had around the staking router was I think extremely interesting I would say I kind of came away from this conversation very actively excited about it and I I've got a bunch of different questions I could ask here but yeah what were some of your high level thoughts from that part of the conversation yeah so I think in general the staking router um is allowing Lido to serve more diff different sets of users um Beyond just this initial you know kind of core user Persona of somebody that wants to delegate the hardware responsibilities and delegate you know um running these these validators to to a you know a curated set of professional node operators so it opens up you know the a customer segment of you know these solo stakers um and DVT stakers um but it also opens up customer segments or at least improves you know the relationship with other customer segments and distribution channels like Dows themselves um you know or even you know maybe a subset of the curated set that is just highly you know institutional and compliant right um and I think it's it's really fascinating just how much flexibility that they have kind of left in design space that they have left to the community to to create these modules um you know things like custom feed parameters um or custom allocation you know parameters right you have the ability to just mirror how the curated set is you know how it deposits are allocated across the curated set or you could do something very interesting you know like sending more deposits to the highest performing validators um or you know fees that kick back to a protocol or something like that and so it almost reminds me a little bit of uni V4 um in that you know it's it's I was going to say the same thing yeah opening eyes right um and I think it it opens up a path right for for Lido to to improve its alignment with the with the community get everybody comfortable you know with with its growth and its market share essentially um you know well also you know in a in a more greedy or I don't know greedy is not the right way but like it it's in their financial incentives to do this right because they're actually it's becoming a better product um so yeah I'll stop there and uh would love to hear your reactions as well yeah I'm really glad that you brought up V4 I saw a direct comparison to that and I think it's there's sort of this converging this converging set of architectures we actually talked about this and it kind of has to do with uh minimizing the surface area of uh you know of your product and minimizing governance and this was a key question we actually asked in season two of this show which is there's sort of a more vertically integrated approach where you do a whole bunch more things and governance has access to all of that or you can choose to be a thinner layer so to speak and you minimize the amount that you do but you also minimize the amount that um that you govern and that makes it more solid to build off foundation on and I think you're starting to see I think uniswap V4 was a great example of that I think Lido is clearly heading in that direction with the staking router I think we we're talking to Sri Ram next week I think you'll probably say something very similar when it comes to eigenlayer so you're starting to see this sort of um these two sets of designs play out yeah I would say I didn't call it the difference with uni V4 versus versus Lido V2 in the staking router is that you know with uniswap users have the ability to choose which you know version of uni V4 they want right which which version with XYZ Hooks and you know characteristics they want to use right and Lido could do the same thing Lido could say all right let's just let the users decide which you know module they want to deposit their stake to right and I think the difference there is that with liquid staking protocols again that would just there needs to be a level of control one to protect the users and two to basically align with the health of the network because you could see a situation where the choice you know gov minimization is great right that's the goal but if you let that choice you know sit with the users completely then I think it's fair to say that'll you know and based off of what we see in delegated proof of stake systems most users would prefer to you know delegate their stake to the most safe you know largest validators right um and so this kind of push pull tension right where you want to minimize as a surface area of governance as much as possible but you also need to basically monitor the allocation of deposits in a way to make sure that you're you're also you know driving forward the health of like ethereum the network itself right because the staking router would be kind of you know I guess the impact of the stake around it would be would be mitigated if um you know less than one percent of deposits were actually going towards these permissionless validators right that wouldn't that wouldn't really actually decentralize light or it wouldn't help Lido decentralize in the way that they want to um so this level of curation I think that's is interesting I think it's an unsaid assumption that many would like to be true but I could see it going in the exact opposite direction that left to Market forces many protocols would prefer to be validated by Professional Services as opposed to sell for solo stakers right I think that's that now I think DBT has the you know to your point about maybe a professional you know uh validator like course one runs a part of that DVT cluster and then there are you know multiple different self-stakers that sort of become a part of that group I think I could mitigate that but I I do think as as it stands right now without DBT I do think most protocols would be prefer to be validated by professionals who will wake up and not only you don't have to worry about them waking up in the middle of the night they'll have teams that just do that so I could see I could easily see Market forces going the other way and putting a discount on solo stickers as opposed to a premium so I think that's probably a you know that's maybe not a popular thing to say but but I think there's definitely the possibility that that ends up happening and then you will have to you know and that then they will be interesting to see the impact that Lido governance has on you know through allocation to different modules of stakers versus just straight up Market forces and it could be an issue for them if you know Market forces actually end up prioritizing a more professional curated set of validators as opposed to the solo guys but one question that I had for you miles is you made a really great point with maker frankly being a potential distribution channel for for something like Lido can you can you explain a little bit and unpack that a bit more because I think that's a an under discussed Point yeah absolutely so you know I think the general idea is that you know folks could deposit ether's uh as collateral to maker and maker you know in their balance sheet Manager Management would deposit that into Lido and um you know to earn yield on it essentially and let's just say that maker or another protocol is so large of a distribution channel that it you know accounts for say like five to ten to twenty percent of all circulating steath out there at that point you know that protocol might be motivated to you know open up a competing liquid staking uh offering right so that they can capture all of the yield and they don't need to share any of the yield with Lido anymore um given that you know it could be a substantial amount of Revenue um but what the staking router enables is to basically you know share some of this revenue or you basically customize the fees to kick back some of the revenue to the distribution Channel um and this isn't that different than some of the growth hacks that Lido has used in the past um with uh basically you know rewarding distribution channels like Ledger or other whitelisted um uh you know wallets or on-ramps with some sort of LDL rewards but this is a much cleaner way to do it right and so you could you could basically mitigate this risk of of competitors like you've we've already seen with frax right who want to who say we've got all this eth sitting around why don't we just you know create our own liquid staking protocol to internalize that yield um and I think that this offers a really elegant solution to sort of let those these relationships grow together um and yeah that was just one immediate thing that came to mind who knows how prevalent that will actually end up being you know with with the with the growth of the staking router but um that's definitely definitely interesting it's an interesting question because what it may what ultimately made me think is you know if you look at that diagram of the the asset side of Steve then you kind of see five or six different modules and I mean you know maybe there'll be some more than that in the future there is another future where there are actually thousands of different modules and ultimately a lot of those end up being individualized modules for say maker or Ave or something like that which would be frankly pretty interesting and I think that would be an alternate way of playing out from the other the other solution that you could do is vertical integration and that's sort of the approach that frax is taking and frankly you're starting to see vertical integration within um some of the major D5 protocols like maker curve and Ave are all converging on very similar business models and they have decided to go in the opposite route of something like like hostu would Advocate which is to just stay in your lane minimize governance you know maximize one you know minimize your managerial surface area they're doing the opposite they're vertically integrating and they're maximizing trying to take on a whole bunch of multiplexity and risk and yeah I am not smart enough to know how that's going to play out but it's interesting to see very different approaches being tried yeah couldn't agree more and I believe like just going back to that maker example they could save maker really cares about the decentralization of the L1 right they could also specify that the only valid the validators in their module will all be DVD or solo stickers right they can basically curate who the validators are what kind of validators they are what the feed preferences are are um yeah so the flexibility adds you know it's a lot of a lot of possibilities here um and yeah it would be it would also be interesting frankly I'm just not creative enough to ask some of these questions but I do remember you might be surprised about what these protocols end up caring about so I don't know if you remember there were Slater proposals for the PSM a little while ago to invest some of that usdc and there were these sort of competing proposals from coinbase and coin shares and the the idea was to reinvest and earn higher yield on that usdc and they ultimately ended up going with coinbase even though the amount of yield that was offered was lower and the reason was is because they could withdraw very quickly remember the function of the PSM is to be a stability mechanism in case you know there's some like depicting event you're supposed to be able to defend the peg whereas the coin shares proposal even though it was actually more additional risk management framework and they were going to reinvest in bonds you actually had to move from crypto and to tradify so the withdrawal time took too long to the fact there's punitive so there might be these weird parameters that are outside just how decentralized is the validator set and what are the fees there will there will be other technical reasons that end up you know determining these modules yeah no I think this it will be very interesting to see exactly what modules you know in the same ways we're very interested to see what people do with univ4 or you know there's a lot to look forward to in in terms of you know what people can do with the with the staking router and and the modules that they create yeah I want to give listeners I want to end this by talking about the restaking module which I thought was frankly super interesting and I wish we had more time at the end of our discussion to dig into that I did want to we initially planned this episode to be uh at least 25 focused on Dual governance and we only briefly mentioned it and I want to at least give listeners an overview of how that's going to work and why that's why that exists um I know Izzy talked about it a little bit but it's this idea of you can imagine if let's say in a future state where Lido ends up winning 70 of uh you know 70 of validators are are within Lido then you could see the co-opting of eth's sort of uh governance and how staking works by a very small set of Lido holders um and often and you there could be a um principal agent problem existing between the the wants of stakers and the holders of Lido the token so what the the solution was to give uh steveholders actually the ability to veto and the mechanics are are pretty interesting there's basically a contract where after a certain number of amount of steath is deposited into this sort of escrow contract that there is a voting period and you can vote down any of the uh like a Lido proposal or something like that um the the other the other thing to mention is that you know Lido is not purely an ethereum protocol you can also you know it's expanded at one point it was on Terra Luna right there is Lido on Solana so it's kind of a supranational uh Dao entity as opposed to a national entity like ethereum to use an imperfect analogy so again it's just like if you want to be a huge nerd and go down the rabbit hole we can link something in the the show notes which is the proposal that Sam kozin wrote that um you know you can take a look at but I did just want to say that was another key part of decentralizing the governance and uh that we just didn't have time to get into in the show that's like directly addressing the principal agent problem right correct and you know I'm trying to pick like an analogy here but you know in the absence of there being actual like you know uh top-down regulation and and people monitoring you know like you would see in the traditional Financial system you know you need to give the holders or the users of these assets the depositors some ability to veto things that are truly truly malicious and very frankly like unrealistic I think um but still that level of comfort that it is possible is what is the big growth unlock that gets the you know rest of the community comfortable um and so I do think that you know the introduction of of the staking router and specifically permissionless pool uh sets or solo Saker sets um along with you know coupled with the Dual governance is is really you know the core of this response that Lido is is putting forward to these concerns in the self-limiting debate yeah so we'll link the the actual Forum discussion in the show notes and if anyone wants to nerd out about that that's that's probably the best place to do it although it has been a little while since that was proposed so there might be some updates in terms of how Sam or the lighter team is thinking about it I'm not 100 sure I want I want to end by discussing the restaking module the possibility of a restaking module that was I thought one of the most interesting parts of the whole discussion I'd be curious miles like what did you find yourself wondering or thinking about when we were asking yes about that you know I think this is probably the edge of like right at the cusp of what becomes uh something that could get voted down because it's too complex by by the by the Lino Dow Community because I uh I I guess my initial sense is this kind of fundamentally changes the product you could look at it that way or you could look at it in the way of you know well we are managing risk already across all these different validator sets and this is just you know a little bit more risk than those other validator sets but nothing we can't manage right but it does introduce complexity and sort of you know the way that you would claim non you know steath or non-native staking rewards um and and things like that and so my sense is that it's something that is possible but um you know I think it's a lower priority for you know as it relates to like Lido's core objectives for the next couple years um I I think they're they they were almost I got the sense that they that they would almost prefer to you know delegate the choice of um whether or not steveholders want to restake to the users themselves um and you know that's that's possible right now since Steve has been onboarded as a um as an LST for for eigenlayer and I'm sure you know there will be eigenlayer competitors that will accept Steve since it's the largest you know that liquid stake in capital base um and so yeah I came out with the impression that yes it's possible but you know it's not something that is a super I don't know high priority but we will see right you know as you mentioned this is bear market and folks have you know a lot of you know care a lot more about risk management at this point and a lot less about yield um and so we'll see how much that changes over time and and I think you at the very least it will be a very spicy discussion you know if and when it's introduced yeah I I tend to agree with you on that I think it is I do fall fall out and probably the hallsu perspective here which is that yeah there's yeah vertical integration if it ever gets explored should be much later in the protocols life cycle I I think right now they should uh try to minimize uh risk and complexity and I think this would be definitely taking that on that said I I view something like this even if it's not Lido and eigenlayer as probably inevitable and I agree I think there's a rich history of we've talked about you know the example would be Bond ETFs so that is actually if any readers of Matt Levine out there he's one of the the Kings outside of barn Jillian apparently he's better but uh you know he has this Trope which is people are worried about bond market liquidity and it's actually very simple similar to this which is there's one Bond ETF but it actually represents many thousands of individual bonds each one of which has their own idiosyncratic risk profile but it trades as one liquid thing and it's actually worked kind of well another example would be this is going to sound dramatic but it's a it's a very similar example of like cdos or Clo's during the housing crisis where you actually had one sort of liquid instrument but it it was packaged about it was a bunch of mortgages that ended up getting packaged in there and you know there was an idea that if you Diversified enough it wasn't really that risky and you can see how after a period of time people might not worry about that it's been working for a couple years we haven't had a problem yet and I I think the the most likely outcome here is that it's not eigenlayer and Lido that end up integrating like this but but some other you know restaking rest it's highly unlikely to me that eigenlayer is going to be the only restaking protocol that exists out there there'll probably be other flavors of it launched maybe you know one that won't be so concerned with the fungibility of positions and the the denomination of the rewards and yeah I think I think that's probably what ends yeah yeah I guess my point is like I think Lido of all of all LST providers that exist today or or come along tomorrow uh is probably the least motivated to do this given their current you know Market position and really they're you know they're trying to reduce complexity right they're trying to grow alignment with the L1 um and introducing something like this I think you know just I could see it much more realistically coming from a competitor that is trying to capture market share from a much you know a much lower position right at the end in doing so by offering outside yield compared to uh you know the safer incumbents like Lido that's I I completely agree with that sentiment I I would just a couple of but you can see how these things shift and change over time right I mean even within crypto maybe a more relevant example would be we used to one of the big advantages that people used to tout was synchronous composability or Atomic composability and now it's like yeah async's probably good enough and there is this uh this idea of you being at the mercy of your stupidest competitor I'm not sure if you've if you've heard that but kind of a an example of that might be a competition that played out in between Celsius and block five I'll let you yeah assume who was the stupider competitor and who is at the mercy of who but I I think you sort of see the my point is that it's just very hard to resist these things in the moment I think that's the the point that I'm trying to make and I I would um you know what do I know I mean people who work at Lido or the you know contribute to the day I've been thinking about these issues for so much longer than than I have but I would just say it's probably a good thing to not get involved with even as time as it might be yeah I think that's fair remember in the first episode of season three Sunny introduced this idea this sort of uh the idea that being an app chain and permission list was an oxymoron I thought I've thought about that quite a bit since he introduced that idea and I've been thinking about it more and more and uh you know we talked about the App Store analogy here but I do think that this is something that protocols that are permissionless you know there's probably some logical limit to how permissionless you really want to be while providing a good product for your end users I think that's an in a very interesting tension to explore and for something like a a staking pool like Lido I'd imagine that there's some amount of monitoring of validators or node operator operations that you always have to do you know we talked about we didn't bring it up on this episode but uh for instance you know it could make sense if there's some internal fee Market that gets developed within Lido it's enabled by the staking module that someone some group or module lowers their fees to zero and they don't monetize that way attract a whole bunch of stake and then they sell co-location services to their validator Set uh or there could just be much more simple uh sort of off-chain contracts you know that you end up colluding with one another so I'd be very curious about um I think this will get played out in time and I'm not sure you know this is all just speculation but I would imagine there's some amount of either monitoring or due diligence or something that these staking pool operators like widow have to do on there yeah I think there's I think the state staking router will actually increase the need for more robust monitoring um and you know I know they have a close relationship with a with a project called rated um and rated just basically you know a node operating a node operator monitoring service um you know looking at things like uptime and performance and et cetera Etc but then you know apart from uh just generally like operationally up monitoring the operational performance of these nodes um there's also the subjective you know uh decision of okay what is the healthiest I guess way to allocate deposits across all these modules right and if you to your point if you just left it to the free market um you know it probably the allocations would would be heavier towards you know the larger safer operators um and so yeah I think um I think that that's going to be you know as as much as like light I would like to minimize the surface area of human involvement um uh and decision making in the protocol um I think this is one area where actually you know if you were to completely minimize it then it would be not healthy for the protocol whereas if you were to you know ossify something like the withdrawal contract you know people would be happy with that um and so yeah I think that this is likely you know points to the reason that something like you know PBS can be enshrined into the protocol restaking could even be enshrined into the L1 but something like liquid staking could never be enshrined at the L1 based off of the principles of you know ethereum there always needs to be somebody monitoring the deposits and the operational you know performance of these nodes yeah I would I would Point folks for a you know this this sort of trade-off in between uh something where human capital doesn't need to be involved as much is there's an old multi-coin posts I think the title of it is Dows manage risk and it highlighted a key difference between maker in uniswap they were actually they were talking about it within the context of how susceptible a protocol might be to forking and the idea being if you're a maker you know one of your core competencies is that you um is that you underwrite a whole bunch of risk right like you're managing the asset and liability side of a balance sheet you're less susceptible to 14 but I think it applies to the rest of these to these doubts as well so yeah I think as it's something to consider as looking more like you know makers operations right where they're looking up at their balance sheet and kind of making sure that that it's it's healthy right um I think that because you can look at it if something like that is analogous with you know monitoring all these um uh the health of the modules and how allocations are split between them um and yeah absolutely that makes you know a lot harder to Fork um but still there needs to be some human involvement there and it's just about minimizing that as much as possible yeah all right miles this was a fun one next episode is going to be great as well so we're going to be diving a little bit more into what we just touched on at the end of last episode we're going to be talking to you sriram Kanan of eigenlayer and we're going to be delving into I'm just getting an overview frankly of eigenlayer the protocol I think we uh you know are conceptualizing the episode as if eigenlayer is also a a two-sided Marketplace in between um stakers and uh sort of middleware operators that want access to that that stake um then you know what is the or what are some of the drivers on the demand and supply side and then what is this intersection going to be with big liquid staking protocols and protocols like eigen layer so I think that's going to be a great episode as well all right buddy I think we can uh wrap it there this is a plumber [Music]\",\n          \"do you have tom brady like jump through a hoop on fire on like kisses for 20 seconds [Laughter] full makeout baby kiss me like a man [Music] before we jump into the app quick reminder that nothing on bell curve is financial advice everything is just a meme hope you guys enjoy all right everyone welcome back to another roundup of bell curves you've got mics one and two yano and vance folks welcome hey guys thanks guys i've got some exciting news um on the on the block works front uh jason actually just accepted a position at kim kardashian's new private equity fund yeah congrats buddy i would i would in a heartbeat like make maker delegate or like kim kardashian associate like i mean there's an obvious choice there that'd be quite a resume i think she's getting money from this i think she's going to be so successful people who are fading her just like how can i i don't get it such a no-brainer such a no-brainer good idea yeah i think she's going to make some like the amount of like consumer packaged goods companies that are down bad that she can just buy turn around and put a sheen on and like resell like i think she's gonna just keep every single new to see brand that launches now is like a person's thing it's like ryan sheckler's pancake mix it's like you know this person's nail gloss you know it's that's like every new brand and she's gonna be the queen of that it's like uh back in the 90s with cisco and oracle when you had the networking technology or the database technology and you had the relationships with all the businesses literally all their their entire growth strategy was just buy up businesses take the products from those business and cram them down the throats of your existing customers like that it worked i mean both of them became 150 plus billion dollar companies and i i mean this is the same thing it's just like the new the new age influencers are the new conduits how do you how do you think she translates it from like leveraging her brand and distribution to being on top at a private equity fund because she can't really take like every single investment that they do do you think it's like expertise that she has in flipping it because she can't like put the kim k you know personal stamp on everything they invest in like how does that work from a fund i think if you're a cpg firm and the options are like sell for cash uh to one buyer or sell for like 90 cash plus 10 upside and whatever kim kardashian you know is gonna do to your brand like you probably take the upside so she has an advantage in sourcing and then i think once it works she has an advantage in fundraising too like no nobody the other guy who that she works with is probably very legit um but like people want to invest in kim kardashian that's the draw i agree well you know it's a slow news week when we open the show with kim k thank you private equity fund seriously i love seriously proud of her though honestly started uh basically flipped a sex tape into a multi-billion dollar private equity empire gotta respect that i respect the hell out of it um no the the same people who are fading her the same people who are like pissed at these like tick tock people that they make 100 million bucks a year it's like that's just the world we live in middle middle curve middle curve real middle curve exactly seriously uh dead dead middle um all right we are like one one week out from the eth merge day right so that's going to be anywhere i don't know if you guys have heard a definitive uh a definitive time but basically 13 through the 16th so we're quoting this on the eighth um i guess there are kind of two angles that we could talk about on this um uh one maybe it's like a little bit longer term like just structural changes post merge um maybe we can talk a little bit about our friend hal press's real yield thesis and i'd love to know how you guys kind of buy into that but maybe we could talk there's a lot of um uh i think people are kind of preparing for a little bit of chaos uh post post merge right so we saw a governance proposal pass on aubae where they're basically temporarily pausing borrowing eth because people are basically trying to get as much eath as they can before the snapshot is taken uh actually before i get into it um me michael advanced when you want to get into like why that like what's going on why the ave thing happened and then some of the like arbitrage mischief that might be might be happening around the merge yep um on twitter i called it slippery business i feel like there's a bunch of positioning that's happening right now both in liquidity pools but also people like the big players kind of like getting ready for what is a pre-planned but like chaotic event which is like kind of where they thrive the most um and so like there's a couple of things going on if you look at the borrow utilization of these pools um where the eath is in them uh you know those are skyrocketing and so like you know i think the the utilization of the ave pool last i checked was like 70 almost um and that skyrockets the borrowing rates so if you're still in there you're paying you know 24 at this point that was the last time i checked and so that's like a very painful trade um and that's happening at the same time you look at the you know spot liquidity pools things like steath and eath really any place where eth is in a smart contract people are pulling that out so that it's eligible for this airdrop um which is like funny because like you know they could have probably figured it out figured out a way to do this with all these assets in the pools but like instead they've chosen to kind of like intentionally have everyone like pull their assets out and then like put humpty dumpty back together again after the merge so there's gonna be all these like weird price despair kind of differences between the pools um and yeah like you look at the price of steath it's like down to 0.95 you look at the price of coin base uh steak diet it's like down to 0.91 um there's just a lot going on and it will be interesting to see kind of it pull apart but also it come back together and at the end of the day we've said this before um i don't think the proof of work chain is gonna be you know very interesting at all i don't think i think it's gonna be a hugely you know profitable opportunity i haven't checked but i think the price is still like in the 30 range uh you know at least the futures price of where where it's trading right now on on some of these platforms i mean you could use like the benchmark of eth classic versus eth you know two to three percent historically is where eth classic has traded but i think one of the bigger points to note uh is kind of what vance touched on last is just the fact that there's a lot of work that has to go in to make this chain live there has to be a client that's live there has to be miners that are ready to go there has to be people who are going to continue to use it there's already been tons of signaling from all the different platforms and providers already saying that they're not trying to support it and i i haven't seen any updates in fact there was something on twitter that i saw that suggested that there was basically zero client work that has gone in and maybe you've got the miners but then you just got miners who are mining something and and nobody can actually use it so i i've i probably paid the chances of this you know greater than 50 not working and not being live for much much you know longer than it it starts out as um i don't know i don't know if you guys have a different perspective but i i'm just not i'm not very long eth pow it's tough to find someone who is honestly um let me ask you guys this are you guys doing any of this like what do you call advanced like cute business or whatever like are you guys positioning this you know i don't know it's slippery slippery business i like yours they're cute businesses yeah like are you like there are a couple things you can do right like you can pull each out of liquidity pools you can sell your teeth for eath you can unwrap your wrapped eath you can move your eth off of an exchange and into like uh like onto a ledger or something because you don't know if the exchange is actually going to give you the proof of work token if obviously it happens so are you guys doing any of that we can't really talk about the stuff that we have in flight um what we can say is that uh like we're not optimizing for getting more proof of work eth like that of the things that we could optimize for doesn't feel like the best uh thing we could do um we're certainly getting ready for it uh in terms of uh if you have any trades on in a liquidity pool that looks like it has this concentration risk you know like that like the safest way to play this is just to be out of those and so we're being mindful of that just from a safety perspective but yeah i mean uh the other side of it is like you know if you get these proof of work tokens what do you do with them um like are you sending them to like like where like bit max the futures like exchange um are you sending it to uh like a dex on the proof of work exchange like the mechanics of getting out of this are going to be very difficult um and i think kind of the sleight of hand that makes these airdrops work for a lot of people uh are a couple number one the exchanges are not gonna allow you to claim your proof of work eth right out of the gate coinbase has said that a number of other staking providers have said that in exchanges so like there's gonna be kind of this artificial uh supply limitation for people who are just holding eth on exchange which is the vast majority of eth um at least that moves um but the people who have it off of uh you know a main exchange they're gonna have to like make decisions on what to do with it and i think those people will be advantaged uh in a moment where there's not a lot of supply so that's kind of like generally how we think it's going to break down but we're certainly not optimizing for proof of work i think these air drops are going to cause way more harm than they do good and like money because um uh there will be inevitably more than probably remember with bitcoin in 2017 2018 there were all these there were all these forks right it wasn't just like bitcoin cash it was like bitcoin plus and bitcoin like one in bitcoin so she's vision satoshi's vision and like the segwit like all all these they're like 20 forks and um so yeah you get the air drops and obviously you want to sell them immediately there's going to be a bunch of scam air drops too though so probably inevitable you end up like let's say i get some pow i want to sell it well i'm going to have like seven other air drops in there and i'm gonna someone you're gonna a lot of people are gonna end up clicking those and just like giving right access to their wallets yeah be safe don't don't mess around with stuff that you don't know what it is um and yeah like we were talking about this before we started recording but the idea that you know like the amount of open interest on dairy bit and hedging volume on ftx would suggest that like a lot of people are expecting this to be a very meaningful event from just like a raw value perspective and like you know probably hundreds of millions if not billions of dollars are expected to be kind of like claimed and sold from this uh that just seems so far out of the like you know realm of reality that i don't think that's possible and the other thing is like this has been you know a multi-year process of kind of like not kicking the miners out of the ecosystem but like just like diminishing their influence and i think this is kind of like the cresting of that wave where you know they're going to kind of put up a fight for proof of work youth but that's really all they're going to get and then it's going to be kind of like you know they get to do bitcoin but they don't have a lot of sway or influence over the rest of the ecosystem which is really good in my opinion i will say this is the most positive i've ever seen kind of like the mainstream media cover crypto is around the merge um so i think that'll be pretty interesting like you're seeing a lot of articles maybe from like new york times or cnn or something uh from these like non uh non-crypto pubs be like this is a step in the right direction for ethereum they're moving towards a more environmentally friendly thing so it's uh it's actually been interesting to see the mainstream coverage of the merge i think i think the big angle here too just that mainstream loves to lash onto even today i think uh maybe it was treasury or there was some announcement saying that uh proof-of-work consensus mining algorithms are probably something that might have to get regulated uh there was some note of that that i saw on twitter this morning and i i think the esg narrative is going to be an important one frankly if if there's nothing else that anybody who's not aware and and kind of uh paying attention to this industry is going to be able to latch on to it's going to be esg because every single time i've i've heard you know these arguments it's like oh well you know nfts they just they're destroying the planet it's like that's absolutely not true but you know okay fine we've got a solution for that um and and i think the fact that you can be able to now point to a solution is going to be a a huge opportunity and and latching on to that i think is what we need to do as an as a base layer ethereum community i agree with that but with the one caveat so that that note they didn't point to specifically like proof of work it was just like energy intensive ways of you know it was there but obviously that refers to proof of work i would say though that it's always just been like from a just first principles thinking about it standpoint it's a frustrating thing because it's not about the energy consumed right it's about the output and what you get for that energy so i agree i think it's going to be a big powerful narrative but i also don't love some of the other like especially like layer one blockchains i feel like have been marketed as like you know uh eco-friendly which i don't love as a i just don't like that as a as i'd read but you know for people who don't get it it's gonna be an easy narrative to latch on to yeah um let's talk about another narrative maybe post uh post merge which is um again credit to hal press who really i think was the first one who brought this concept into crypto real yield so that's a concept uh you know that's very familiar to uh you know traditional finance when you're talking about the returns that you get from fixed income and bonds right so there's like the nominative yield of something which is what you actually get paid and then you subtract out inflation right it's a more real representation of whether or not you maintain essentially purchasing power um that i think hal was kind of the one who outlined that and applied that concept to ethereum i know you guys are kind of supporters or kind of buying to this idea can you just explain like what does real yield mean in the concept of uh the concept of eth and how is that going to change post-merge yeah so really what's happening right now is the there's an inflation rate that is being applied to ethereum every single block and um i don't know the exact block number off the top of my head but there's a number of ethereum tokens that are created every single block every 13 to 15 seconds um what that leads to is an inflation rate of somewhere in the three to four percent right now um and you can think of that as being the the necessary component of the value ecosystem that goes to compensate the miners who are running these proof of work change as we just discussed energy intensive have to be able to subsidize the cost of running you know massive server farms essentially that suck up a lot of electricity cost money et cetera et cetera additionally the hardware cost of actually running that what changes with proof of work obviously is you move from a proof of with proof of stake is that you move away from the proof of work the amount of cost that goes into it drops so therefore the amount that you need to pay the security budget drops as well generally the concept that hal is talking about is this this change when you move uh from a from a high inflationary rewarding mechanism to something that is actually potentially deflationary is really the the mechanism that he's talking about so you know as a staker uh there's the possibility based on throughput that you actually ultimately end up having less ethereum at the end of the year than you started um so that that's one component of it the other component of it is after eip1559 you have 80 90 percent of the transaction fees being burned to increase the amount of deflation that's going on in the ethereum network well all of this leads to this component of what's the actual yield that you're getting and his theory which i think is accurate is that the yield that you can get by staking a token is the inflation area is the total yield minus the inflation and the total yield could be you know whatever it is post-merge but when you have a reduction in inflation you increase the amount of total yield and we've seen a ton of other staking opportunities you know we've all seen them throughout the industry where you've got massive staking yield but that staking yield is being subsidized by inflationary rewards and it's it's just the the separation of the concept of what's real versus what's nominal um i think that that's really kind of the key point to hit on here the the things that are like important to think about uh when you think about ethan real yield are kind of their [Music] you know counterparts in both the equity and bond world so in the equity world um obviously you're getting paid you know for some stocks at least like for instance like meta doesn't pay a dividend um they have a stock buyback uh and that's going to be probably i think like 40 billion dollars this year but they're also issuing you know 20 25 billion dollars of new stock per year and so like you know some of it's kind of like your ownership increasing some of it's decreasing but like meta doesn't have a yield so there really is like it's apples to oranges there and if you think about you know treasuries like the 10-year or the two-year or whatever auctions they have going it's you know the real yield of those treasuries but they're selling more of those at auctions every single week and so there is this concept in most other asset classes but ethereum is is the one that's the most unique because it's on a block by block basis it's it's super transparent but you also have the potential of this thing getting much larger in the future um and so for a lot of people i think like you know the real yield of whatever it is six seven percent is exciting um but i think the opportunity for that to be like a quasi-venture bed as well is unique when you look at you know every other asset class and the dynamics of both supply and potential deflation i i guess i mean just to put it in like super simple bell kirby type languages i mean basically if you think about it from that the dap kind of layer the inflation right is basically that's just customer acquisition costs right you're basically giving away ownership tokens of your your platform and you're generating something that looks like a yield from that but if the inflation rate is higher than the yield that you generate then your owners or stakers of that platform basically losing value on a year-over-year basis uh and i guess you know one thing like one i guess the good parts about bear markets in general is like okay there's less hype and excitement and just like fo mowing into stuff so now is the time to actually think about like generating real sustainable value and that's kane's whole kind of push with real fees as well exactly but maybe maybe to go back real quick i think one component that's important here as well is um there's this there's obviously the concept of real and nominal yield and you know the the financial theoretic version of what your asset is worth versus you know the discounted cash flows versus you know the ownership percentage that you have and and what have you i think the other component that's really important to note here is that when you have inflationary yield and you're you're adding more assets to the tradable amount of assets that are in the ecosystem you know to also take hal's point is that the flows and the supply and demand of these assets fundamentally change as well when you there are more inflationary rewards tokens uh sure you're earning those and maybe they're locked maybe they're not locked depending on the protocol but if you're earning those tokens eventually that just means that there's going to be more supply to sell and so even if it's just you know theoretical um on one end i think there is a structural component to it which is the flows can can you actually break that down a little bit exactly like which which part because like price is just a function of supply and demand in general right and flows kind of describe uh more like the demand side of that so well i'm actually not exactly sure i follow like how does the um how does the flows kind of relate to what we're talking about here yeah so i i think um your point is is a good one in that the inflationary reward could be thought of as customer acquisition costs and you need to have sort of a top sticker price to incentivize people to to join an ecosystem jonah protocol state trade whatever whatever the incentive model is and i think that that's important at the beginning in the same way that you know uber subsidized the car rides uh in san francisco here for a couple of years at least when they started with uberx i remember it was like 250 to go across the city and you can kind of think of it in the same way eventually you have to get to a point where they're charging enough and their take rate is high enough to where uber the company can make enough money and in in terms of the flows if you have consistently you know unit economic negative transactions going on uh you're gonna ultimately end up losing money and the way that that the way that that comes through is you're gonna have more people additionally you're going to have more people who have these assets who are going to be able to sell them on the market uh and so it may it may look nice and and get users involved initially but eventually it's going to be something that you have to move away from otherwise you're not going to build a sustainable model yeah yeah i get you on that it's kind of going from like a like a not like a deeply unprofitable tech company but like a slightly unprofitable tech company it's like a very profitable tech company and you know that's kind of the the structure that drives the flow because you know if ethereum was a tech company and it was you know deeply unprofitable and had no assets they're just basically selling more ethan to the market to keep itself going and now they're just stopping and so there's just less sellers um and there's less sellers by 18 000 eats per day which is meaningful like we we've talked about this before but like we think probably there's like a 1 to 25 ratio of you know fundamental flow to like quant flow um so that that matters when you think about that in that context you know what's just funny to me about this whole discussion is um you know it's been around for you know like seven or whatever years now um so it'd be very logical to be like okay this is the time and the the life cycle of the company where you want to transition from being deeply unprofitable to like we want to think from just growth at all costs to like unit economics right that's like a super traditional framework or way to think about it i feel like if you polled the rest of the world like how risky eth is and like where it should be in its life cycle they would have a very different thought so actually in a way this is almost like getting ahead of the curve here right yes yes but it's not the same you know it's not like they're going through this process to become profitable it you know that would be how you look at something like an uber who's looking to go public per se who like needs to have positive unit economics so you can get you know the valuation for your next fundraiser or your ipa whatever it is the the thing about ethereum which is unique is that the technology is changing this is a move in the positive direction for the protocol so that you can enable further developments like you know all the things that are on the stealing roadmap like sharding a proof of state network is a requirement to move in that direction and and so it's it's both and in a really really unique way where you have this implicit change in the unit economics but you also have the positive direction of the technology and that in the second point is actually leading the first which is unique interesting do you um do you see the concept of real yield does that apply to like non l1s like eth would you use a very similar framework to look at like a dap or like a dapp chain or you know it basically is basically can you kind of borrow that concept and apply it to non l ones couldn't you could you apply it to any to any app or protocol right any real field can you apply it to non-crypto things too or is this why like i mean melton tweeted that thing and then how was like this is really dumb but i think she was basically just saying you have the inflation rate you have treasuries at three percent inflation eight percent so the real yields negative five how was like this is an incredibly dumb tweet i don't know why why i'm too middle of the velcro to know why i was a dumb tweet but like can't you apply this concept to anything i i didn't see the tweet but the thing that's unique about l1 is that they have to pay for security um and if they don't have that you know they're cooked um when you think about dapps like they don't have this like fundamental blockchain uh security need uh at least they don't need to pay for their own native currency and so they kind of are by default like more profitable than your average l1 just because they don't have as many costs um i think your l1 probably has your average l1 probably has more users than your average dap at this point but i think that's going to change um and yeah i think it's always there's always been the question of like okay you cool you have this dap what do you do with the inflation um and those feel more like those decisions around what do you do with it feel more like you know how do you spend your growth marketing budget at a tech company that's small to medium-sized than like how do you re-architect this new asset class this new you know kind of technology paradigm it's like in games you know in digital game ecosystems what it ultimately comes down to in in mobile in particular but if it's somewhat based as well is that it comes down to ltv minus cac and and that lifetime value minus customer acquisition cost and that is more of the equation i think when it talk when we're talking about dapps in particular to vance's point but ultimately we're getting to the same same conclusion here which is you just have different variables flowing into ltv and different variables flowing into cache whether it's adap or its base layer yeah it follows that you're gonna have a lot few like you know in ten years you're gonna have a lot fewer l ones that are profitable than you will dapps um the dapps just have much less cost it's much harder to get to the critical mass of users that's required to sustain an l1 from a security perspective um and like even look at bitcoin you know it's huge has a ton of users the market caps gigantic right now it doesn't have enough fees to secure its future long term um and so i think we're really going to see the consolidation around kind of like kane's point i think is particularly relevant to the dapp sector but i think you're going to see the consolidation in the l1 sector as well because like you know 20 years from now like let's just pick on like you know harmony um who's really going to want to subsidize like who's going to want to subsidize the cost of like running those validators it's like non-trivial especially if you're underwater on them it's probably going to be like the foundation the investors that's probably it and a lot of them will shut down or just use ether's security layer as a result that's my guess at least you guys see uh suey raised 300 million dollars congrats everybody oh all right i think that concludes this section here let's talk about um the the coinbase institutional maker partnership yeah i know you uh you were talking about this for you want to lead us through uh what this is what's going on yeah give us a good description of it not a bad one [Laughter] don't [\\u00a0__\\u00a0] this up uh i mean it's like it's pretty simple uh maker so maker has this thing called the psm there's like 5.2 billion dollars of uscc in the psm uh coinbase uh prime which is uh they're like institutional team they bought tagome and created this institutional team and that's coinbase prime now coinbase made a proposal for maker to transfer 33 of the usdc out of maker's psm so that's 1.6 billion dollars out of the psm into coinbase primes custody uh the reason they would do this the reason this is good for maker is uh this would give them one and a half percent yield on that usdc so one and a half percent yield on 1.6 billion dollars is 24 million dollars uh so that's 24 mil in additional revenue that maker could be earning um and that's that's kind of the yeah that's the proposal so one point of clarification i think uh is like what is the psm and basically what does that usdc do what is the usc usdc doing right now the ustc sits there and serv is acts as collateral for basically the die and it earns and the thought is that it earns no yield so yeah like one of my pushbacks on the forum i was like 1.5 feels low and they're like well until we have a better strategy 1.5 is better than zero so it's fair are there two buckets as well json for that usdc there's the usds like protocol owned usdc right and then there are customer deposits and this is only for the usdc that maker owns right correct yeah exactly so i mean if you look at like the yeah if you look at the balance sheet of maker right now it's like liability like die eq is the liabilities and then the assets are the psm and the user vault so the psm is like what is like the maker owned assets and maker can invest those assets and that's like you know die is collateralized by those assets and then there's the user vaults and users own those assets and the maker protocol can't touch them so basically liabilities die assets is the psm and the user vaults what this would say is that so like on the asset side you have two buckets it's the psm in the user vaults this would kind of create like a third bucket so you'd have die as the liabilities and then the third bucket would be you have user vaults the psf and then you have like what what maker folks think of as like safe instruments so this would be like things that generate yields very small amount of yield highly liquid like liquid within a couple of minutes um and that would be like short-term data yes for example like three-month t-bills yeah so yeah yeah i think the biggest um the biggest concern with this deal is like where is coinbase generating the yield um because if they are if they're doing something that feels safe like kind of similar to t-bill investing like that's probably fine that's a good thing whatever if it's something like unsecured lending to crypto market makers that's probably not a good thing and i probably wouldn't vote for that so i think that's like i think that's the unanswered thing is where does coinbase generate this yield i mean maybe even like a more umbrella question is like what's the benefit here at coinbase which is kind of the same same thing right what like how would they use this uscc how would they generate an additional in addition to the 24 that they have in cost how would they make a spread on that like yeah they they can it's like any bank it's like they can they give out one and a half percent and they're gonna make more than one percent one and a half percent that's what i was going to say it's like any it's a bank you know the bank well it's that interest mark it's a net interest margin business as well so they're making spread on that um you know i feel like the last time we played this game we broke basically everything in crypto like i like i so i think it's there's always a question of what they're doing with this money um and i hope they're just putting it into t-bills or like you know the 10-year which is like yielding you know 3.4 i hope they're not just like turning around and lending this on a like on or no collateral basis to funds uh probably it's a mix like at the end of the day but the reason i like this proposal for maker specifically is because it helps its regulatory resilience like if uh if uh coinbase is holding all the usdc and then the treasury department sanctions the psm the the maker uh like you know contract apparatus uh like you now have to kind of deal with coinbase as well like that usdc came from maker um it just makes it gives at least you know maker uh it ropes coinbase into their corner and makes them kind of play defense on their behalf so i really do like that um it's also kind of like a lightweight version of the uh the rune proposal that he put forward uh two weeks ago like he's talking about like you know getting a bunch of youth and going yield farming with it like this is like all right let's just send the usdc to coinbase and generate 1.5 so it feels like a decent middle ground um but again like maker maker has like this like i can't tell if it's really good or really bad governance where like it seems like a million things are happening at the same time and it's kind of like going off in all these different directions like what part of like the phoenix you know max decentralization playbook is like sending all your usdc to coinbase um like yeah some of it feels a little bit confusing i was gonna say this feels like total at odds to roone's proposal based on that last point in general i mean this is like literally the opposite direction which is let's go more in the put the stuff into centralized custodians and you know just one comment on on coinbase in general you know we use coinbase at framework and um you know they they are really upstanding in terms of you know their relationships with their uh lenders and providers and uh customers partners i i would not be nearly as concerned with this type of lending as i would be something you know historically at least like the celsius stuff that has been unraveling so i'm not nearly as concerned about you know us playing the same game again um but this i think the big point here is that this and we're going to see how people view it but this is in the total opposite direction to runes post in my mind but isn't roone's post he's like for the next three years there's one though there's one north star now accumulate as much eath as humanly possible and we can do things that like aren't as decentralized like bring on real world assets like do basically basically my reading of bruins thing his updated one last week or two weeks ago was like do anything humanly possible to get as much crypto native collateral as possible as much eath as possible then in three years we can like pull things back now i don't think things will actually get pulled back in three years but i think that's like the north star in in his mind so and and by the way like usdc like they're already using real world at usdc is just a wrapper on t-bills so it's uh it's already like you already have these t-bills you know like t-bills on chain or like 10-year notes on chain like not synthetically because that's like basically illegal but you know like a real representation of them the problem that they're trying to solve here is like maker can't talk to the outside world they need someone to do it on their behalf um and like i think that's a pretty profitable position for coinbase to be in um same with all of these other centralized exchanges like just the amount of capital creation that's going to happen in crypto is going to be quite large and then interfacing with the traditional world is going to be a big opportunity um i think this is like a move that like fits with runes proposal it's a very light version but it gives them room to expand it where like what if they send coinbase like a billion die in a year you know coinbase now has to go out and defend die and you know in the same cases tornado cash like go bankroll lawsuits and like you generally want the most finance player to be fighting the biggest battles and that's certainly not maker and it certainly is coinbase and so i really like it i agree you know to go back to this uh that it is a timing thing and it's not necessarily ultimately at odds with the rune post but to one of the things that vance can have touched on but to bring it back is like who signs the legal agreement on behalf of maker like it's not like you're gonna have you know a lending agreement with coinbase without some sort of legal agreement or some sort of agreement in general is every single maker holder expected to vote and like sign their name on the dotted line you know like there's this there's all the details of how you bridge digital you know on chain with something that's centralized off chain that yeah are yet to be discovered yeah i mean i think within these dows i will say any any doubt you dig deep enough there's usually one or two people behind this so like you dig into this proposal and there's it's the growth team so there are teams at makers and they're like full-time employees who work on those teams uh and so like this was the growth team and specifically with on within the growth team there's i think it was this woman jen who on the growth team who like did this deal not very different than like a block work sales person going out and selling coinbase on like a sponsorship deal or something you have a cell phone you know so but it is very different in that you you have i mean this is like legal structure question like one of the biggest one of the biggest dows out there like one of the biggest d5 protocols we were we were gonna sign a contract with them for something and they were like we can't sign the contract because we're gonna we have to turn into like a c corp and we're going through that process now i was like interesting so wow not a doubt they're like no no we're still going to like keep our name like the x dao but uh we have this new idea for you oh they're like it's this game they're like it became too big of an issue to sign contracts and like it was really preventing our growth so but i think that's that's right there and like this maker thing and all this this this is the most important question in crypto right now like this is the biggest dichotomy is like the people who are basically saying like everything needs to stay super stay super decentralized like create censorship resistant platforms uh at the sacrifice and detriment of like maybe expanding your your market and gaining market share and things like that and then the other folks are maybe saying like okay i'm a dow but like man my market share is 10 i could be like 50 by the end of this bear if i just like centralized a little more create created permissioned pools and like created a c corp and like those are very at odds with each other and you're seeing that pop up every single week all over the space this this also may be like more of a bear market phenomenon where like the ten years yielding more than like basically yeah um so like you know in bear market you see higher yields outside you see capital outflows but not really like i mean there have been a lot of stable point redemptions but there's still a ton of them in the bear market you just see the opposite or in the bull market is the opposite you see the capital flow in um and yeah yeah i mean like in the bull market maker was not sending you know usdc to coinbase um that's for sure so some of these things can pass as well you know you stay in crypto long enough you see you know the seasons change i thought that was a funny uh thing like because a year ago everyone was talking about yield being the trojan horse that was going to draw you know uh you know capital into crypto and now the business bottle has essentially flipped into importing tradify yields into crypto which is just like a funny complete flipping of that narrative but maybe that's just a temporary bear market thing because it makes sense like crypto's higher growth it should have higher yields yeah i would think well i mean this goes back to real versus nominal yield how much of those yields uh in the bull market were real yeah well yeah yeah but even in trad fights like deeply negative real yields so by the way they're putting this money into three month t-bills i think it is um the three-month t-bill's at like 2.9 percent so coin b like coinbase is basically that's a 1.4 spread that they're making 14 million whatever call it a day yeah call it a day yeah do you guys think um there was an article of financial times did an article a little while ago um it was like the the title of the article was stable coin issuers hold 80 billion dollars worth of short dated us government debt and they had this little chart of like the biggest holder of t bills uh it was pretty funny to see like circle was above uh berkshire hathaway on that chart which is pretty well actually um but uh do you guys think that's a positive or a negative thing um because on the on the one hand you know i what i've kind of heard from analysts in the like guys like jim bianco has made this point that you know regulators start to be very worried when entities hold that many t-bills because what they're worried about is a proverbial like run on the bank so to speak right what they're really worried about is like uh hey like what if you know basically usdc faces a flood of redemptions and then you have to sell you know an enormous amount of security like treasuries basically and like that's fine today even like 80 billion is like a lot but look at how fast usdc expanded like that could be 500 billion or there are money market funds like a trillion you know uh so like i think that's the on the one hand it could be like invite more regulation but on the other hand maybe it's like the us government just wakes up and is like hey we are planning on running a trillion dollar deficit for the next forever uh and we need people to buy these bills so like this is actually kind of a convenient thing you know what i mean like i kind of see it going either way you can you can buy them but like if you need to sell them just like let us know because let's give a sweater like it's like oh you're concerned about this like high yielding asset and like everyone buying it in the underlying liquidity like sounds kind of familiar yeah um i don't think this is like a problem in the next you know 10 years but i don't know seeing this year where bonds had their worst years since literally the civil war in the us you're like okay cool if this pillar goes like what else are we investing in just like stocks and crypto like how does this work yeah it's kind of remarkable how little of this has been kind of like thought out and planned especially within the context of like massive trade deficits interest rates rising and just like qt nuking the liquidity and treasury markets i don't know like seems like you probably want more people to buy them and if they need to sell them like you should probably figure out a way to interface with them instead of just like holding them at arm's length and like not allowing them to touch the traditional financial system because like selling 80 billion of spot you know t-bills i don't know how that goes down probably not that smoothly if you need to do it i think that last point's the the best one in that uh they're now forced to take you seriously you have to be someone that they want and need to do business with and so because of that they can't stamp you out there there's existential threats to them if they were to do something draconian and and onerous in it and so i think there's that but then you know you get taken seriously and and everybody's always talking about like oh no regulation it's going to be terrible like we're going to kill the industry bad regulation will kill the industry good regulation could make the industry and i think that that's where we really need to actually like be sensible in in terms of you know it's not it's not a black and white situation and like for this industry to grow as we've seen over the last few months like certain things should have been regulated probably um and i i think we should be at least willing to welcome that if if we want to see this thing grow to the size of i think we all do side note on regulation um i actually i was listening to this this podcast called acquired i know if you guys ever listen it's a great great podcast they did this episode on standard oil which everyone should go back and listen to it's a phenomenal story but one thing that blew my mind was you know when he was when john rockefeller was doing this back in you know late 1870s 1880s it was actually illegal to do business in multiple states you know that how wild is that so they got around it by doing this thing they had like a trust and they were like oh yeah there's going to be a trust and there are trustees and the trustees leveraged something called a joint stock company which like no one had leveraged in the 200 years since it got created and like they did all these things uh that were very like not technically in the spirit of the law but they found this weird and they had to act and they you know they took pains to like make it seem like they were not directors right of this big thing just reminded me um very much of like how dows like bending over backwards to not you know to appear like they're operating in a different way than they might actually be today and eventually the uh you know they broke up standard oil but then he basically wrote the playbook for what the modern day corporation looks like so he was kind of right at the end of the day but there was some friction in between getting from point a to point b i mean there's so many funny cases of this over time like cryptography used to be uh regarded as like a like a weapon and like you know we have people on our team who instead of like sending their cryptography over the internet back in the day they would you know print it out and fax it because that was like how you could like communicate your work with other people um it was illegal to do commerce on the internet until the late 90s um like there were all these bills and all these pieces of regulation that made the internet and cryptography possible and like this is probably you know a good segue to the the kind of like tornado cache uh sanctions like this is always how it was gonna happen uh or the tornado cash velocity like this is always how it was gonna happen like something was gonna be bad or the administration would regard it as bad we would fight it with a lawsuit and you know win or lose like we're gonna have more clarity and i think like i would put more odds on the winning side but that's how we kind of move the industry forward like it it's unfortunate that it has to be at the cost of like people in jail and stuff like that but like these are the battles that are kind of necessary to fight in order to push the space forward yeah um yeah i think the one thing that people almost like treat as a constant um or like never consider the fact that actually crypto could get so big that we just change a lot of the existing regulation and the way that we think and that's like i know that sounds a little extreme that's like kind of my base case you know there's a lot of stuff that i think if people like really sat down and thought about it like that doesn't make a whole lot of sense the way we do kyc there are all these studies about how inefficient it really is right i think um you know actually after this this you know this sell-off in the beginning of this year you look at where a lot of like tech giant like huge success stories like twitter and snapchat and pinterest like where they ipo'd versus where they're at today it's like level or down it's nuts so it's like all of that value got created in the private markets and i i just don't think that's fair to be excluding people from frankly like i think that changes philosophically agree with you uh i mean i think even brian armstrong from coinbase said uh and he's been over the course of at least the last four or five years he's always said uh we have the rulebook we should just operate in the confines of the rulebook in the last couple of years or in the last year in particular i think he's he's totally changed his tone um you know we probably need new rules i don't know if it means we need a new regulator but you can't put square pages into round holes consistently when we're dealing with regulations and laws that existed decades or potentially even centuries ago uh we're talking about a new asset class that existed less than 10 years ago in earnest yeah like like the the financial security apparatus is basically transition to the spectrum of like safety or opportunity and there is like some truth to the meme of like you know you'll eat the bugs and you'll watch the netflix and like you know but at least you'll be safe um and your life may not go anywhere but like you know you're gonna be super safe um on the other side of that spectrum is like it's kind of open you know there's more opportunity there's more danger you know you might not be as safe and like we've gone so far over to the side of like safety and you know eating the bugs that i am i'm hopeful that there's you know a pendulum swing uh in the process but you know a lot of this is post 911 patriot act yeah and that's not going anywhere that's definitely not going to work but you know one last thought here is you know if you just look at d5 and you say okay composability transparency and global access are probably the the three biggest components tenants of what makes d5 powerful or the promise of d5 you can maintain basically all of that in the same structure as financial services as just today and have the advantages that make it such that you know i i truly believe that d5 will ultimately be on the right side of regulatory history here because it provides a better system for what financial services should enable right you know if you have transparent transparency if the role of financial oversight is to monitor and guard and protect against you know opaque financial institutions well if you get rid of the opacity and you add transparency that's a huge advantage and i think there's very few people outside of this industry that get that right now i've got one closing question just to bring it back to maker and then we can move on to because i want to talk about binance and their busd they're stable but what is the you know from a first principle standpoint what uh why would someone own and hold die i suppose uh if it really is something that's just backed by usdc then isn't it just kind of usdc with extra steps like what's the first principle's reason for why die should exist if we go on this route uh it's cheaper um in terms of if you're like die is mostly a stable coin that uh has a utility uh for lending and borrowing you know like you get die it's cheaper than ave it's cheaper than the centralized desks so check um there's no receipt token so like in the us there's this weird thing where like if you get a receipt token potentially that's like a taxable event um with maker there is no receipt token and so that isn't you know you're just getting the stable point against it and so like that gives people marginally more uh confidence um other than that you know they're kind of apples to apples like we kind of most interact with the usdc um and i think there's also like additional risk of like you know the roadmap for usdc is pretty clear the roadmap for maker is like a million different things on you know any given day so yeah especially if it stop if it stops being not pegged to the or pegged to the dollar like at least we would think differently about putting assets there i'd like to give a shout out to jeremy lair jeremy alaire like is i remember do you remember in 2018 it was like they were the darling remember goldman invested in them they had they had poloniex they had like all these different businesses and then it was like they're on the down there was the sheet that got passed around their their their like private stock was trading like 85 discount or something and they just went all in on this one thing and absolutely crushed it so shout out to them legends and cms came out of there one of the biggest props yeah one of the biggest pro otc desks they had the like uh a competitive app to coinbase like a great retail wallet too yeah bob loneax or us i don't know so bob poloniex sold poloniex yeah they got instrumental yeah they rented it they rented it yeah the other interesting thing that i've i've seen from circle uh past like you know couple hours jeremy alaire kind of like teasing that like maybe usdc gets into the bridge game so smart where it's so fun it's so smart right like you just have like the on either side of the bridge you can just like mint usdc and burn it on the other one um that's such a no-brainer and such an improvement on what exists like it's it's inevitable that coinbase or circle or someone gets into the bridging space i think i like it i think circle is going to be you know a really awesome company i do worry about like the amount of control that they're getting over the space like if they're dictating our fourth choice and also like our bridge choice yeah like at some point you know they're going to be kind of like the financial security apparatus themselves and yeah i just i there's a there's a very like the the line they're walking is so thin it's like you know like half tradify half the time like the other half like your d5 only jeremy layer could really do that i don't i think uh just from a higher level perspective like i think um i don't think that crypto ever gets enormous and successful without at least like the tacit if begrudging approval of the united states like i do think it's important to i think you have to build uh you should be building like censorship resistant architecture and everything but we live in a world you know i i don't know i'm not ready to like live 100 in the bits like i don't know when i take my like when i leave this podcast like i'm gonna be in new york you know like i you know so i don't i don't know i i hear i hear these arguments and i agree with them on a first principles level but it's also like i'm a citizen of the us too and like i don't believe they're evil and i think if we build if we um i i really like the framework of like being big enough and like owning enough treasuries and like hey like we're a force to be reckoned with like take us seriously and by the way like we're gonna kind of do things how we want is that cool i i'm not 100 sure we ever get to the full cipher punk vision of like entirely uh i just don't see a really uh a road map for doing that yeah but but mike this year in the behind this right now in the bahamas it's super nice that's true dude that's true yeah what what if that vision only works in the bahamas you know that's not the end of the world either i guess i guess that's not i'm i'm a believer in the crypto cypherpunk uh vision of the future i think it needs to be both um but i think like you know if eth you know had gone to 10k at the time uh of last bull market with the amount of value locked in defy and even if it does in the future that's more than a trillion dollars of value locked in default like at some point you just got to call a win a win like we don't need to be like a 100 trillion dollar asset class to be like you know considered successful we can do it because the assets themselves have value and they're experiencing this like exponential move in their prices every few years and people use it as money like you know we we kind of do need them we kind of don't need them i think we can pick our battles but over the long term um i think the biggest outcome is integration and i mean i would say probably the the best entrepreneurs that we see that are building at least starting in the in the us are basically ready at a moment's notice to pack up and move and it's just kind of that mentality that you have to have right now because i i don't think you could possibly i mean i'm sure you could come up with one but it's it's hard to imagine a more um uh aggressive and uh detracting regulatory environment in the u.s right now for crypto or anything related to crypto um and in a lot of ways rightfully so especially what's happened over the last couple of months with centralized crypto lending in particular but that's that's one bad apple one bad case um and it doesn't represent the entire industry so right now you kind of have to but and and that's where this like crypto punk version of the future has to has to exist because that's right now kind of the only logical and viable one uh but eventually if we want an order of magnitude higher than what we're talking about or multiple orders of magnitude larger it's gonna have to be something that that threads the needle between the two let's um uh i want to get you guys view on binance and then just kind of like the stable coin space like writ large uh we haven't really i don't think we've talked on the show about like d5 protocols launching their own stables but just to give you an overview of what happened uh this week so starting september 29th binance is automatically converting usdc usdp and tusd stablecoin balances uh into new uh binance you know busd deposits at a ratio of one to one uh they said this is to enhance liquidity and capital efficiency for users uh basically if you're a user of binance you'll still be able to withdraw from your you know chosen centralized stablecoin but the amount is just going to be deducted from your busd balance um uh notably can you throw the volume of these pairs up or just like coin gecko you know binance see their biggest markets i mean on the surface i know that this kind of got you know negative feedback and i actually had a couple of people text me and be like hey are you worried about usdc like it seems like it's being de-listed from finance i don't actually read that as being the case here like i actually think this is a really positive thing because it you know it basically unifies all the all the trading pairs within binance against the single asset which is busd so you don't have the fragmentation which i think i'm sure we're going to see here in a minute um and you're still able to use you know deposit and withdraw all the different stable coins or just you know on on the platform represented as a different asset seems seems like a positive move yep i mean two thoughts the first one is tether is just like getting taken to the cleaners um you know that like tether was always kind of like the asia stable coin uh and like where what you would trade on finance when you traded on finance busd was kind of always this thing where you'd be like hey like i can use that maybe i'll get a reduction fees but like generally didn't really care about it tether is like probably in danger from this um in a significant way and my second thought is like this doesn't really matter for usd my third thought is like the ecosystems are fragmenting right like western phi is like usdc like asia cz phi is like busd and tether is kind of like in no man's land um but yeah the ecosystem is fragmenting and this is kind of like one thing that just solidifies that here's a weird aspect of this is that but busd is just white labeled usdp or pusd basically paxos is stablecoin so binance and coin is just white labeled paxo stable coin which is actually the most regulated stable coin so it's the only stable coin that's regulated by the nydfs or something like it's got all the regulations because paxos deep in with the regulators um so like you know i feel like binance is usually kind of uh a little maybe plays it fast and loose with the regulators but they're but their stable coin is actually just this white labeled like highly regulated stable coin it's pretty interesting it's regulated by nydfs was like one of the first stable coins to get their approval when that happened i was like what the hell is going on but it makes sense now i didn't know what the the pack says yeah i met someone from paxos at a like unrelated like dinner party thing the other day and you know whenever i meet someone from crypto i know it's like oh paxo says hey man like what's going on like good to hear like meet someone else who works in crypto is like crypto no blockchain was like yikes yikes flashback 20 to 2017 raging indictment uh right there this might be like a 3d chess move to move on on shore um for cz with binance and i i i wouldn't be surprised if there's some interesting tricks up of some slaves yeah i guess i just listened to this podcast on john rockefeller so i'm seeing the whole world through the lens of standard oil finance is just like this whale that is still just gigantic like if you just look at volumes uh i cried like dude everyone's like oh is sam banquet freed ft no dude no one's even like close to what binance is doing and you don't see him on the cover of like magazines and all that [\\u00a0__\\u00a0] um the last 12 months have been the same show i i don't think you know there's a reason why we haven't heard too much from cz but i think we undoubtedly will hear a lot from him soon yeah there's like you'll be in like a random city and you'll like turn around and just like sam's face like right in front of you like a gigantic billboard or painted on a wall it's he's like everywhere but i think uh long term those feel like the two that are going to be very competitive with each other and i think it's gonna be awesome to watch them kind of like try to like maneuver each other uh i think both have kind of like strategic mistakes uh recently like where's ftx state death product where's finances or i guess binance probably has something but like isn't quite scaled yet um where's ftx's stable coin is it coming like you know there's a lot of stuff that ftx needs to do to to even make it dent and finance um yeah it's a bit more of like an optical illusion at this point i've got an i've got an open question uh for maybe you guys know the answer to this actually but when um when coinbase had their earnings a little you know because the narrative that brian is trying to push right is that we're transitioning away from this transaction based business where uh you know the spread that we take is going to fall over a period of time to something that's more like a you know they've rolled out something like a subscription but really they had this like 150 million dollar line item on their quarterly top line which was like i forget what they called it like services or something like that and it basically the you know they didn't actually detail what this was but i think that's the income that they're generating from their uh like east staking like e-staking that you can do on the platform but i ca i have a lot of trouble backing into that number actually um because you can see how much eath they have uh and it doesn't really make sense and i remember that they bought bison trails a little while ago and bison trails does uh you know they're like the back end for like kraken's staked eath product right the the eat that you steak on christmas trails is the back end for cracking steak to eat are you sure about that i'm not sure that that's correct no no staked staked is the back end for exactly because it's cracking a card stick yeah but that was post but remember that was post they already had a staked product at that time they they bought steaks and they integrated it into something and i'm pretty sure that bison trails is interesting it does it doesn't matter the point the point being maybe someone can help explain what that line item is because there was also this uh expense cost that was like associated with that revenue which basically outweighed sam bankman freed thus in a psyop you know like basically pointed this out to everyone and no one no one really caught on to it but he was basically like hey that 150 million of that revenue that they generated here's 150 million expense that's not associated that's not associated with anything uh yeah so um if anyone could explain uh anyone who has any knowledge i'd be very curious for because i had a lot of trouble backing into that that line i mean i i think one you know i i don't have the answer off top of my head but um or nor do i have any information about it but i think it is interesting to think about the transition that coinbase is about to go through and thinking through where their long-term strategic value is going to be derived from i'm hard-pressed to see it anywhere other than staking and kind of the services that you could get from staking and having assets on chain uh or having assets on on the platform and i know that they've started to roll out cb eth um you know there's discussion around them having sort of an institutional product as well um i i would i i think you know staking is gonna become really the dominant factor here and they bought bison trails coinbase cloud you know there's a lot of opportunity here for them to move in the services uh in sustainable revenue direction in lieu of transaction fees i think have you guys heard of alluvial we have we have yeah so they have that whole partnership right that they were supposed to be and like they just kind of rolled out their own alternative to olivia which is like cb eth um well i i think there is sort of a distinction here um i believe cb eth is taking 25 percent of the rewards and that is sort of the cut that you can expect if you're using cb probably something that is fine for retail to get that cb moniker on your on your eth probably not something that's going to fly for institutions i i wouldn't be surprised if they're two separate products interesting okay cool before we move on from uh ftx or binance let me show you guys the traffic differences for the two companies just to show you like this is their web traffic so this is last month binance had 90 million visits ftx had 11 million which is actually really impressive for ftx um yeah it's actually higher than i thought it would be 17 million unique visitors which is just nuts um ftx had two right like if you look at the geography i bet actually if you add coinbase i bet coinbase would be in the lead in the u.s and then yeah let's see yeah like so here's here's coinbase's business just the us right and then actually ftx is bigger than coinbase and russia turkey argentina ukraine everywhere else but binance has a 90 market share so i mean it just goes to show you like you you can't you can't like just advertise your way to having like a global brand you know you can get tom brady you can get matt damon you can get you know whoever you want but you know the time in the market and just like your first mover advantage and compounding that and like the you know every single time coinbase is mentioned on cnbc like 10 other people hear about it it's it's uh yeah i mean i think these are how the rankings are going to stay probably oh my god look at this number it doesn't feel coin market cap 140 million last month so keep in mind right remember binance ends them so right i mean all of the like all of these like thinking about coin market cap versus binance coin market cap you go you check on the website you see the prices these days you just usually immediately exit um finance it's like you're just like you're going there you're logging into your account you're placing a trade like the fact that they have 75 of the volume of coin market cap is wild it's such like a more engaged project that product that i would have expected that to be much lower than coin market yeah i will say that you can buy your way to success and ftx for how new they've come onto the scene totally but what what are the like i i think ftx is going to be super successful it's a question of like what do you do now that you've done all the things like do you have tom brady like jump through a hoop on fire on like kisses for 20 seconds [Laughter] full makeout baby kiss me like a man we're definitely keeping all of this yeah um i i hear you though i agree i'm not you know what actually i think is also interesting to draw a distinction between the type of marketing that you can do as like a c5 uh as a c5 company in crypto versus like what would work in for like a protocol you know like we talked about like i think one of the criticisms like yield farming as a customer acquisition strategy is that it's really expensive but i would argue there's like you couldn't have translated that into just dollars to spend and advertised and like got companies to where they were right like the uni-swap airdrop it's like people love to be like oh it's like 150 million or whatever if they had spent 150 million dollars on advertising what would that have done nothing like i just don't think it's even possible you just hit the nail on the head of the the network effects that are derived from tokens that's the power right there it makes sense it makes sense though like equity is much more expensive than dollars um so like it's not it's kind of like you probably spent like you know a billion on these airdrops versus like the 150 million cash equivalent um yeah i think one thing just to kind of tie some of the previous points together one thing that will differentiate between the three you know coinbase ftx binance going forward is product differentiation if you have the ability to have certain assets certain products that others don't in certain geographies that will be a distinct advantage now they're all three large enough to have enough captive audience to be able to have something that scales like let's say you can start trading options on securities on ftx us like i don't know if that's in the market in the in the roadmap but like let's just say like you can do that right that changes the dynamic of the ftx because like all the people who potentially want robinhood access now just go to ftx because you can get a better service better product there like that i think is the differentiating part going forward but if you if you really break it down who's going to be best positioned to be able to go after these opportunities is it the one that's based in the the regulatory unfriendly us and trying to work with regulators or the one that's based offshore that has the ability to operate freely and or not freely but a little bit more freely you know like there's a distinct advantage you know what else was a telling um i thought it was very interesting the way that block five versus celsius got treated by regulators like celsius like this is this is supposed to be the strategy right like you if you do everything by the book then the regulator should you know if if you're sitting down like being a strategy of this then the regular should call you'd be like hey seems like you guys are putting in best effort like we don't really get this space like what should the rules be and like you would ideally be able to help influence what those rules are and it seems like blockfi was basically trying to take that tack and strategy and do everything by the book and celsius was just kind of like yoloing into yield but like no pretense of being you know regulated or doing anything by the books whatsoever and how did it work out for those two strategies block five got 100 million dollar slap on the wrist which was actually a huge deal for them at a time when they really probably needed that money um i guess celsius blew up because it was celsius but like you know what i mean they kind of got punished for doing the right thing so to speak so what's the incentive i block five wishes they had that hundred million dollars i mean uh it doesn't always apply but sometimes it's better to ask for forgiveness than permission i know we're i know we've been doing this for a while uh i want can we i want to get you guys to take on this so rare thing can we talk about that yes oh man let's bring it back to the pre-framework days uh so contacts uh for those that maybe don't know vance and i prior to starting framework started an nft platform called hash leads that uh i think was the first license first major ip rights holder for blockchain based digital collectible we signed a contract with the nfl pa and had digital collectibles nfts representing uh nfl players in 2018 and 2019. i'd say there's a lot of lessons from that experience which we don't need to get into here one of them is the ip rights process and what happened this week which is hilarious you know that everybody seems so surprised by it so rare who's been historically an epl english premier league focused platform for their nft platform uh started to get into uh the nba and taking some share and and some uh of the ip uh probably ipvalue let's say from uh other existing mba partners um and you know this is exactly how the ip rights usually play out and you know we we've saw this firsthand with the way that our deal was struck there were multiple players um multiple deals that that were made we were the only one that ended up signing it and historically the way that it works is you have multiple rights holders for the same category usually in the like three to five range but not more than that and then over time they whittle it down and eventually have an exclusive contract um and and so this is i think just um at least from our experience what we would have expected to happen exactly is the way that it did um but unfortunate for those that had assets on other platforms that they thought they had exclusivity yeah it's uh if you're a user and you think about like the physical cards like the tops cards the baseball cards versus the panini baseball cards um you know there's a chance that in ten years uh maybe panini doesn't and they're one of the cards companies or maybe tops doesn't review their license great news you still got the physical card sitting in your shoe box you know it probably gets more valuable because it's been discontinued here the nft they don't have the rights to those pictures anymore those colors those players all of the on-field photography like those just have to go to zero and you have to make cards blank and so you know it feels like the legacy ip holders and like the decentralized collectible movement are just like fundamentally at odds because one party just doesn't really get it and i think there's good reason right like you don't want to just like license your ip in perpetuity to somebody um and so i think that's the reason that you know all of the ip that we think is the most valuable has to be created by people that are you know in crypto a startup you know like a larger company but that's where all the interesting long-term stuff is going to come from like the crypto punks nobody's ever going to tell you that you don't own your crypto punk again that's the difference i have a just because i guess this is coming to the forefront like a whole bunch of way just talking about ip if you guys had to like divide out value creation in between like the ip itself and then all of the work that goes into propagating the ip right so like building an infrastructure i'd like to invest in and buy more ip distribute that ip whatever like how would you break out the value there i guess what do you mean by that example the point the point i'm trying to get at is a lot of the i guess what i'm what i'm thinking about is um i guess what i was thinking a lot about recently is like pseudoswap so pseudo did their token we don't need to like talk but it's not important but like it is this whole narrative right now of like uh you know is our nfts jpegs with or like all coins with pictures or is this like a new way for artists to like monetize their ip and uh i think there's a fundamental misunderstanding like ip's really important like the stuff that you create but then there's an enormous amount of work and value that gets created by like investing in building new ip and then distributing that ip and i think a lot of the argument that's taking place right now is just based off of a lack of understanding of the work that goes into curating investing and building new ip basically uh so that's why i was kind of trying to get your sense of like well it was you're trying to value disney as a business like how much is their ip portfolio versus the infrastructure that goes around that ip that you make a park right out of the idea of mickey mouse basically if you think about like uh like the physical baseball card market for instance um the value is divided into two pieces there's the value creation all the stuff that happens on the field with the players their popularity the sports popularity and then there's the distribution which is basically panini and tops have relationships with all the card expos and all the card trading shops and like the nfl and the nba and the mlb are not set up to do that they don't want to do that and so like all of the val like the value is kind of like mostly created on the field but like there's a substantial chunk of it that sits with the distributors in crypto the distributors basically have no value um you have a bilateral connection with your user i can send them tokens i can send them nfts i can message them there is nobody that can shut off my access to that person if i'm a brand and so like that's why nfts in my mind are able to charge you know and give back to the artist such a large percentage is because like the distributors have just been cut out um and you know like do i think pseudoswap is like you know an anthem to like the nft movement kind of like you know the whole the whole idea is like enough value should be created and captured by the creator to give them some sort of share uh so i wouldn't be surprised to see other markets that are more vertical kind of like take a hard stance on this in terms of opinion and just try to like curate folks that really respect and want that both from the artist and customer side i'll kind of take maybe a slightly separate perspective or different perspective in that you have gotten rid of the distributors or frankly like the base layer blockchains are now the distributors and the users pay for them directly so like get that out of the the value chain but what has changed is you've basically shifted all of that towards what's what's the utility of these assets you know and in the case of so rare you know they built this game and they're building more games and and supposedly you're going to be able to use these nfds mba nfts in the games that they're building that was also the case for us with hashtags who built like a fantasy football game that you could collect and buy sell and trade these these nfts so that you play them uh and win more in in the game i think you kind of have to shift from just having these be static collectibles that either increase or decrease in value over time to being something that has to have its value derived basically from pure utility and utility comes from like the software that the nft has itself the creator's ability to integrate it into applications that they build or basically the the potential to have integrations outside of the ecosystem and so you know the the portability or the um the overlapping of other applications i think is an important one but it does shift it's not necessarily the supplier it's it's more of like it's more of the functionality that is imbued within the nft that drives the value yeah i don't have much to add to this does anyone have plays of the week tweets of the week memes of the week names of the week i have a meme i created it i went i went silent for like 10 minutes because i was creating a meme yeah hold on how'd we do kim the go give him the goat a lot of text on this one a lot of text too much text for the meme yeah so accurate though i like it i like it i'm trying to think of other i was trying to fit some like middle of the bell curve meme in there there's also did you guys see uh this hilarious video this guy saw hillbloom tweeted this video of um the first astronauts the outtakes of the astronauts do you see this no this was amazing this is outtakes of nasa astronauts trying to walk on the moon oh i've seen this before yeah is so good it's so good i thought uh the moon landing was faked i thought this was a stanley kubrick production i have it on good authority from the internet [Music] i mean the moon does look pretty flat here so mike you got one no i honestly might play it like play i don't have a meme of the week my play of the week is just i actually um i think it's respect to kim for starting the private equity fund i also think it's respect to the carlisle guy who went on a limb and did this because if it doesn't work everyone's gonna be like yeah dude you started fun with kim kardashian you know uh so i i just have respect i just have respect for the entire endeavor i think it's i love it i i wish them both success honestly that's why it's cool she's doing in the bear market too like that that's super bass that's how you know she's savvy a great yeah all right fellas i think we can call it there fun see same time next week take it easy [Music] you\",\n          \"all right everyone welcome back to another episode of bell curve before we jump in quick disclaimer the views expressed by my co-hosts today are their personal views and they do not represent the views of any organization with which the co-hosts are associated with uh nothing in the episode is construed or relied upon as Financial technical tax legal or other advice you know the deal now let's jump into the episode hey everyone before we get into it today just want to give a quick shout out to this season's sponsor Rook close to a billion dollars worth of Mev has been taken out of users pockets and that's just on ethereum and that number is only getting larger unfortunately Rook thinks that it's time for a change and they've built a solution which is going to automatically redirect that Mev back to where it belongs into your the user's pocket so you're going to be hearing all about them later in the show I'm a huge fan of this team and what they're building so stay tuned to find out more welcome to the intro episode the kickoff episode to season four I'm very excited to be joined by haasu we're going to be taking a journey into the dark force and exploring Mev haasu welcome to the show man yeah it's good to be back uh to do yeah speaking about Mev and doing some podcasting I'm very excited to do this with you yeah me as well me as well um so let's just get into it and folks who have listened to previous seasons of bell curve will know that the point of this episode is basically to lay out some of the ideas that we're going to be exploring in depth later in the season and you know I think it would be a very cool outcome if both of us you know we're going to lay some of these things out and we're going to kind of you know speak through and understand what our opinions are going into the season and I would love it if we changed our mind about a couple of things you know after we've discussed these topics with our guests I think that'd be a great outcome oh yeah um I I when we designed the guest list um there's a bunch of people on there who have have not talked to so far so there will be a lot of new for me in these conversations and frankly that's uh that's a big reason also why I enjoy podcasting and why I enjoy um doing this season on Mev because it allows me to meet new people and get New Perspectives on on Mev which is just a fear that is constantly evolving yeah I agree so I want to start um you know maybe to introduce the first big topic that we're going to talk about um which is what does equitable distribution of Mev look like across the Mev value chain there's a lot to unpack there so maybe hosu could I Tee It Up to you and could you kind of break down this concept right that many people be familiar with but what the Mev value chain is who are the actors and then what do we mean when we talk about what is equitable distribution of value look like across that chain most people know Mev as the money that can extract from reordering inserting censoring Etc the the list of transactions that they put into a block right so I would actually go and generalize that to say it is any money that or any value that a privileged actor can extract in a in any system as a result of their privileged position and so if you use that definition then um all of a sudden you start to see Mev everywhere for example central banks you know going out of control printing money that leads to hyperinflations you see um you know that's that's Mev right Google cheating in the ad auction um that's Mev there's there's just so many forms of Mev everywhere and um my bull thesis for crypto is actually that people want crypto in order to Escape Mev in the real world right they want systems that are more fair that are more decentralized where there are fewer privileged actors in them that can result that can extract less Mev and so um yeah I think um I like this kind of this Arc um that uh the smev and crypto and maybe outside of crypto and yeah so um I think we need to make sure that the that the systems that we built in in crypto RS resilient to mevs possible because otherwise store thesis doesn't work out hmm and I I think there's you know to borrow a a phrase that um Stefan right has has used is there's kind of this idea of Mev dystopia and let's say that let's go into this season assuming that Mev is an inevitable outcome when you have different systems like this and to your point that could be a crypto economic Network that could be a central bank that could be Google's ad Network let's say there will always be privileged people in these sorts of systems and there's always going to be a way to extract value but there is probably systems that have structures that enable better more fair outcomes and then they're probably more black box opaque systems where maybe the outcomes are good maybe they're not so good so maybe let's even back up for a second there and when you're designing these systems right because flashbots in many ways is involved in designing these economic systems what are some of the principles that you sort of use or think about oh that's such a great question what are the principles um I would say one of the one of the main principles in reducing Mev is the idea of competition because when you when you have competition for example uh in the Mev supply chain we try to have competition at as many um layers of the stack as possible when you have competition between uh different block builders in order to buy a block from the next validator then the result is that they start to compete on price and they start to build up bit up what they are willing to pay and the value that makes more money if you go down one layer then if you have more competition between searchers you know for the same Mev opportunity they start to build up the value of that opportunity and give more money to to the Builder one layer before that let's say if you have more competition between wallets or applications to minimize the amount of any whether the user exposes then there will be less money lost and so I think competition competition to do better to be more Innovative and to find better Solutions that's one of the main principles a another one would be privacy that's very big for asset flashbots because if a transaction is private then it's much harder to extract Mev from it because you don't know what the transaction is doing you can't simulate it you can't say Let me let me front run this transaction for example because why the transaction is is private it could do like a million different things and so whatever you do is purely speculative right um so what else I think giving control uh over their transactions to users I think that's a big one so a lot of a big reason why we are talking about Mev is such a big topic is that users and wallets and applications for a very long period of time did not take control over their transactions they have the they have the power to do it right they they could for example use a DEX aggregator instead of using unit swap or they could use the wallet that that protects them from Mev that routes their transactions through a private channel to minus or they could change their RPC endpoint in metamask to to do the same thing right um there it's not like options are not available but this is a complicated topic and yeah it's just very hard for people I think to see the differences and see um to to Really compare different options and um and no one even hit them but I think one of the peniculous sides of fmev is that it's often invisible to uh to the eye right you can look at your transaction but even if you look at your transaction in in uh in ETA scan you won't necessarily see that you've gotten sandwiched for example but because the the sandwich would be then in in different transactions that come before before and after your own transaction right and so it's um it's many things it's it's a lack of um awareness lack of visibility a lack of sophistication and yeah so it's it's really a multi-pronged problem that we are slowly chipping away at all right so competition privacy redistributing web to users those are you know kind of philosophies and ideologies right so I want to kind of map that across the value chain as it exists today and my question to you is so if we kind of lay out right there's kind of users in wallets um then there's Searchers Builders relays validators and when you're you're designing how Mev should flow through that entire value chain those principles that you laid out I totally agree with my question is what do you do when the principles that you're trying to design a system around bump up against the natural economics that organize that system and what I mean by that is there's every incentive for actors in that value chain to uh vertically integrate or create these little deals in between each other and consolidate so that it looks less and less like the design ideologies how do you deal with that bumping up uh yeah basically you have to include that in your design so you always have to assume I think in in distributed systems design you always have to assume that people act on their own best self-interest and nobody is um yeah nobody does something for someone else right every Everybody Just does what's best for them and um and you need to understand what these strategies are these self-motivated strategies and then you need to design design the system that it's robust and it gives you the guarantees that you want even when people just do what's best for them hmm and so I think we can so we we could go into an example right so for example why I would say so some people say that they have different schools in Mev which I actually don't agree with and I'll tell you why in a second so there's this is a straw man but this there's there's the school of uh democratizing access to Mev which which just says that um well we can't it's uh it's like it's very difficult to minimize Mev so let's make sure that the the access to the best block is available to all validators so validators can stay simple and decentralized and we we isolate the the centralization and complexity of block building into this new role in the block Builder right and then we just we try to make this role very competitive but we isolate it first and so this has already done a lot in order to curtail the the level of vertical integration that that you were talking about right and then the other alleged School says we have to minimize Med instead of democratizing it right democratizing is the wrong path and so um I think these are not um competitive at all I think we should do both all the time right you have to minimize what you can and then you have to democratize whatever is left because if you don't then you will get centralization a divided layer which we don't want but back to the original point so there are many uh Mev designs that have been proposed in the past that are not incentive compatible for example if you just ask validators to run an alternative uh client that orders the transactions in a way that doesn't maximize Revenue to that validator but that has some kind of that is somehow opinionated about what Mev can be extracted or can't right then um whoever validator will use that um yes they will have less Mev in their block and they will arguably cause cause less harm to users but using that client is not incentive compatible and um it just means that most valeras will not do it and um and those spell letters who who do extract Med they will over time outperform and crowd out the value that as who uh who ignore the Meb right and so um this shows that it's it's not even so even if you're willing to sacrifice something uh in order to protect users from any vs available it's not even in it's not even it's not in your own best self-interest but it's not even in this in the best set interest of the system itself because all of the solutions must be coherent at the system level there's no individual player here who can solve this except for the user and so that's why we are so focused on educating the user to use solutions that that expose less Mev to begin with yeah so let's let's talk about because an enormous amount of discussion thus far in Mev has been kind of dedicated to the validator level right in trying to enshrine systems where we don't have centralization at the and that's kind of the proposer Builder separation right which is on the roadmap for ethereum but there's kind of this new Force which I think is going to be emerging in the Meb value chain which is a little bit higher in the you know in the structure of the of the value chain which is kind of the user and wallet layer and that so we had seen you know previously kind of block space auctions happening at the the validator level and now there's talk about order flow auctions happening closer to the wallet and user layer can you talk a little bit about that Force yeah I'd love to um so the idea behind order flow auctions is that users don't just send their transactions to the public mempool or even to directly to a block Builder because they by doing that by sending it it straight away they just they give away the Mev value of their transactions if if we assume that you have a transaction to make mic that has let's say 100 of Mev attached to it for example because your transaction takes an inefficient route through D5 it trades on instead of trading on all exchanges equally it only trades on one exchange and so it creates an Arbitrage opportunity um then what the autoflow auction does is its auctions off the right to execute your transaction or interact with it in some way that allows someone else to plug the Mev that is attached to that transaction and if you combine that with the principle of competition then what you get is that you have different searches competing for the ride to pluck the Mev from your transaction and you get the same effect that happens when Searchers compete for the same Mev opportunity with the block Builder what you get is they start to bid up the value of the opportunity they start to bid up the right to take your transaction but instead to instead of paying it to the block bill or the validator they pay to you as the user and that allows you to reclaim the Mev value of your own transactions so you know what is a little bit exciting to me when I think about this and we'll talk about the regulation is going to play a role in these systems that we're talking about we'll get to that later but you know the the analogy has widely been used when describing me via payment for order flow right and that's uh you know to use the way this works in traditional tradfy kind of markets is brokerages sell their order flow to internalizers like a citadel Securities right and that's why Robin Hood has been able to offer zero trading fees to its largely retail user base which is kind of dumb dumb order flow is the is the it's the word that these people use and if you actually take that to its extreme right Citadel Securities did something like some incredible number like 18 billion dollars or something like that in in profit last year so what's kind of cool what you're talking about Mev redistribution to the user is the next logical step to that is actually to say I'm going to compensate you and pay you actually to trade so not only can you trade for nothing but we're gonna return some of that the fees that we got to you which is an exciting concept to me I think it's very interesting yeah it's uh it is very interesting I I would say that I think on a common sense basis you can never get paid to trade and so it's a very tricky idea because you you are paying something otherwise they wouldn't give you that service right it's it's just that you're paying in an invisible way and I think so there's a lot of things um oh I think payment for order flow has a very bad reputation um I I think the concept itself is sound but um I think what I dislike the most about it is basically the in transparency of uh of how much you pay right what what's actually the cost of um getting a particular trade executed and I think that's that's where we can do um a lot better in defy yeah you know something that's funny about payment Florida flow for me to because you're absolutely right right it but to me payment for order flow is almost a an example of fee preference so you know when they're when you have financial markets right people need to uh there's infrastructure that supports that and the people that create the infrastructure need to extract fees in some way so it used to be you know brokerages would charge you it was actually a very honest business model in a way but people didn't like it because there's this very seen noticeable fee up front right in the form of it used to be much higher but even with Fidelity it used to be you know five dollars or something and now it's now at zero instead people have opted for these invisible fees that you're kind of alluding to and you know what Citadel does is when they get your order flow from Robin Hood a bunch of people buying GameStop they don't trade directly against you that would be illegal but they understand and this is statistical Arbitrage which is happening in crypto and I want to get your thoughts on is they understand that when people are buying GameStop AMC is about to move so the GameStop people don't get run over but in a sense the AMC people the people that are about to buy AMC are going to get it at a worse price so is that front running I don't know that's a weird philosophical question right now I think the regulatory apparatus in the US says it isn't but you know it's an interesting question to pose it is a very interesting question um I wouldn't consider that I mean I'm not sure if I would consider that front running I mean in a sense you are using the information of one user to um impact another user but I I'm also on the other hand not sure if if there's such a thing as the right to buy AMC at a stale price um this is this reminds me of the The Flash Boys um debate right where all of the um the old trading firms were complaining that um they were now no longer able kind of to to buy like still Market maker quotes on exchanges because they were starting to update so fast and so on yeah so I'm I'm not sure it's it's a very interesting topic for sure I agree all right I want to keep moving through some of the ideas that that you and I want to explore so one other big question that I have for you and this is you know I know that flashbots is working on this in the form of suave but even that kind of Mev value chain that we laid out there's actually kind of another dimension to it because ethereum has adopted a modular scaling roadmap right so not now not only do we have um the main chain of ethereum but we have layer twos right in form of arbitrum or optimism or base and then the idea is we might have you know either app specific um kind of layer threes that sit on top of those those two so each one of those systems mevs being generated so one thing that I think we're pretty interested in exploring and I'd love to get your thoughts on now is how is Mev going to work in that world of uh modular chains built on top of one another so I think the first thing that so first of all I completely agree so um the roll-up Centric uh roadmap of ethereum and not even not even just that I think it converges and you had this great season on kind of the modulus take in Cosmos I think that the world of Cosmos and the world of ethereum they are converging in the middle um I think and I mean this is not a this is not a new opinion but I think the ethereum um Community has been better at executing um and distributing and so I think my my money was was to be on um the ethereum ecosystem out competing the the cosmos ecosystem from here but nonetheless technologically speaking they are converging and I think um in it will be very hard to say in the future if a particular project will be an ethereum project or a cosmos project just because of how the different layers can be mixed mixed and matched right so what does it mean for Mev so I think intuitively speaking the Mev accrues to the execution layer with the caveat that actually the Mev accrues to like technically speaking the Mev accrues to whoever gets to order the transactions um and so usually the execution layer has some control over the ordering so they they can decide to forego that they can opt into being what is called um a layer one sequence roll-up or a based roll-up right um or opt into any kind of shared sequencing system and in that case the this alternate system that now sequences their transaction now accrues all of the Mev there might of course because the the the the execution layer has the ultimate right to decide who they want to give the right of sequencing who they want to Outsource that to so they still have a lot of economic power over there and can can hopefully negotiate some form of profit share so that would be my that would be my first uh comment on that uh Mev in the modular stack then how is it going to look I think one interesting takeaway is all of these layer 2 sequences right now are centralized and all of these layer twos have road maps for decentralizing their sequencer but if you look at what the sequencer actually does it's a Combi it's basically the accumulation of what the block proposal in the block Builder does in ethereum layer one so it's almost like you're taking the you're turning back time right it's like we go back into pre uh pre-muv days on ethereum and so I think that shows you that this um when when this layer 2 sequences actually complete their um decentralization roadmaps that that they have today their drop on Mev is far from done I think that they will all have to struggle with the the same problems that ethereum uh was struggling with um about uh basically there being very inefficient Med extraction um the uh the Mev introduces a very big skill differential into block building and because many because abstraction in the public mempool is very inefficient you now have a strong incentive to vertically integrate between Searchers and and welderas and yeah all of these things will be true on layer 2 as well and so long story short I think what we need on all of these layer twos is a form of PBS meaning proposal beta separation meaning we need to um we need to abstract out the the role of the block Builder and yeah I think these are two points that I'd make what the modular stack and yeah let me know if you wanna dig in any Department yeah I have more questions um so some and some of this I know the rules are kind of being written in real time but you know I think it's a good heuristic kind of rule of thumb that the Mev will accrue to the execution layer that makes intuitive sense to me I followed that here's my question to you right now and I'm going to ask this question within the context of a single sequencer world where with the assumption that we're going to move to a decentralized sequencer set over time but in the single sequencer world right let's use the optimism model for now so you basically get to bid to run the sequencer for a specific period of time and order the transactions and if the profit you can extract ordering that transactions in that period of time exceeds what you have to pay then you're in the money and everything's good but the difference in between you know being having the ability to order transactions at the base validator level at ethereum is once you order those transactions the block gets you that's the settlement consensus layer but this layer is still one layer up so you could order those transactions but then how do they get sent down you know how do you make sure that the the way you've ordered the transactions will settle in that way so you can extract your profit ah okay so um a sequencer today uh in a layer 2 does four things basically so they um receive transactions from a user they um decide on some ordering of these transactions and then they give the user some receipt of where they have been ordered so that's what we typically know as a pre-confirmation and then number four then they send the ordered batch of transactions onto the data availability layer God and that's what basically creates finality uh from the perspective of the layer two so from from the perspective of the layer one these um you basically still need a validity proof of this batch uh that it leads to a valid State transition um or you need some fraud proof window to pass that basically proves the same thing right so it's this is but this is about convincing the the layer one uh Bridge so from the perspective of the layer two once the um once the the sequence has posted the data availability batch or the batch of transactions onto the data availability layer the transaction is is practically finer my next question for you here and this is the last on this topic and then I want to move on to some other topics is you know the amount of fees that validators can extract from from Mev and then there are other Revenue sources that's the security budget they're securing the ethereum network right so I see a couple of different competitive forces here that might impact the security budget of ethereum one you have the emergence of order flow auctions on main chain and then you also have these sequencers right which extract their own Mev and those I see is am I correct in seeing that that's kind of uh taking away from the the revenue that validators can extract and should that be a cause for concern for the security budget for ethereum um yes so I think in the broadest sense if we if we could if we look at a um a a build is if you look kind of a sequence signed a builder as one of the in the same then yes any money that is extracted by any other participant in the supply chain that is not a a validator that lowers the security budget of ethereum but I would say that Mev should not really be counted towards the security budget at least that is how the ethereum core developers think about it so I think their CME vs kind of an add-on but it's not something that they want to enshrine it's more something they it's definitely something they want to minimize over time and um and so Justin I think it was Justin Drake who a couple years ago and should introduce this idea of the minimum viable security budget or it may have been vitalik I'm not sure but the idea is that the the minimum the minimum necessary amount of security should always be paid from inflation um nowadays we it could also be paid through the base fee so right now the base fee is basically set by the most recent degree of congestion in the network so the network was very congested and the base fee goes up and the network was not very congested it basically goes down but you you could change this this base fee based on other factors as well so for example if uh if the recent security budget was too low then you could increase the fee and so on right um it's just not guaranteed that this will lead to more demand to transact and so it's It's Tricky um but I don't think ethereum will have the problem or the need to do that um because if ethereum has a lot of holders and um I think that um ethereum can pay its security budget through inflation um and yeah that should be enough it should not have to rely on Mev yeah and there is one topic that I know our first episode we're going to be talking at tarun chitra and Justin Drake and I know he wants to talk about Mev burn as well um so we'll we'll pick his brain on that hey guys quick break from the show here I want you to imagine something for me imagine swapping two stable coins on chain paying zero dollars in gas and instead getting a rebate of two thousand dollars this is something that's actually happened on chain to understand how I want to introduce and thank the season sponsor Rook zooming out for a second the current state of affairs at Med is billions of dollars so far have been extracted from users Pockets using Mev Rook is coming in and saying enough is enough blockchain should drive value to their users and the applications they use it is time to leave the hobbyist era behind us if we want to move forward we want to get this right that's why Rook has built a custom blockchain settlement Network and it's one that gives you full control over the entire transaction life cycle today you can connect to an open source rough node The Rook protocol will automatically match bundle and auction your orders and transactions in seconds with zero gas overhead also any Mev that's discoverable along the way will be returned to you the user created as a collaboration between the industry's top mechanism designers and Mev Engineers Rook was built from the ground up to be scalable safe and programmable you can get your own mempool choose searches and Builders and link your mempool with others to discover even more Mev you can Define how the Meb is shared and delivered as well and what could basically process anything from transactions to meta transactions and more this is the way that blockchains basically should have been from day one so if you're a user listening to this here's what I want you to do I want you to go to your wallets go to your favorite app your node provider and say Hey I want you to be working with these guys rock I want the Mev that I create to be redistributed back to me if you're a developer and you want to stay ahead of the game the best way to do that is to follow them on Twitter they are at Rook or even better yet slide into their DMS they are lighting responsive they'll get you set up today and if you do slide into those DMS as always please tell them that I sent you I I want to move on to you know I think many people are familiar at sort of a high level with the idea of what a Searcher is and what a builder is um and you did actually a great episode on on Common Core a number of years ago I think called interview with a Searcher and we're going to be doing kind of a 2.0 version of that with a couple of Searchers in the season as well but I would love it if you could just give for people like help formalize like what does the search or landscape kind of look like today and maybe if you could kind of touch on like Searchers that optimize for long tail Mev versus short tail Meb and if we could also touch on this idea of statistical Arbitrage kind of sex to Dex Arbitrage as well that'd be great yeah so I think that there's a couple of ways to slice that pie one of them is to look at the different forms of Mev that exist um the biggest one by far is arbitrage so Arbitrage meaning there's some trade opportunity and if somebody makes that trade then the opportunity disappears for example an asset is underpriced relative to some other asset or the same asset on a different exchange then if you buy that asset and sell it at the same time then it kind of evens out in the middle right and um so Arbitrage I believe represents about 80 percent um of the Mev and I want to caveat that by saying that Mev in general is very very hard to track a lot of it is invisible a lot of is happening between ethereum and the centralized exchange or ethereum and some other exchange and a lot of it is not easily recognized as Mev basically and um that said so there's Arbitrage arbit charge is the biggest ticket no matter how you slice it then you have sandwich attacks um and that's when you uh that that's when you basically buy an asset before someone else buys it and then you sell it right after them they buy it at the at the higher price and and you sell it back at higher price which makes you win something at the expense of the the sandwiched person and uh the last one um the the last one is is liquidation so sometimes lending markets have to liquidate collateral um of someone and then they just auction that off have some mechanism basically for selling that and it's typically Searchers who who do liquidate that and so this is one of the examples where um applications actually rely on searches in order to do an essential job for that application which is to recapitalize um their balance sheet um so of these um I think that um so Savages have gone down over time a lot actually um that's for a couple reasons I think for one users became more sophisticated um there's better tooling so more users understand how to use Dex aggregator more users understand how to use um a private RPC endpoint like flashbots protect that allows you to send a transaction directly to a block Builder without it ever touching the public member but arguably the biggest is just a existence of Unison P3 which led to more concentrated liquidity around the current market price um and uh and that basically made it possible to set tighter slippage limits and and generally have have less price impact in pools and it made um sandwiching just a lot less um profitable Arbitrage is is an is an interesting one because uh a lot of Arbitrage used to be atomic and I think this is a theme that I wonder if the Searchers we talked to will confirm this but this is this has been on my Mev bingo card basically for a couple of years um which is uh which is basically that Atomic transactions will disappear except for when the markets are going really crazy uh why then because then basically statistical Arbitrage players um turn off their models because they are afraid of getting blown up and so only the the most riskless trades basically get executed um and that's when kind of time time for for Atomic habitats to shine but so the reason why uh statistical Arbitrage and that means statistic laboratory means it's um it's a form of trading where you take balance sheet risk so you buy an asset and and there's a small period of time or there's some period of time it may be very very short where you have to hold the asset before you can sell it so that is um more risky of course because the asset can go down while you hold it right and so it's not Atomic it's not riskless and um but the reason why this form of trading would dominate nonetheless is because uh if you don't have to do it atomically if you can do it statistically if you can internalize a trade you can generally do the same trade cheaper you can use less gas you can bid a higher price and you can ultimately win uh the the right to execute that Arbitrage with the block Builder and in any case so any kind of trading like that will happen at the Block Builder level anyway so it's already today and this may be also interesting to mention um many of the top traders in D5 are also block builders so they don't even go the step of the search anymore and submit their their trades as a search or two different block Builders they may do that also because they want to maximize their inclusion guarantees so they want to maximize the chance of being included on chain when they have a profitable trade but they also want to be a block bidder because that gives them much greater control over their trading strategy basically they can make the trade at the very last micro second before they have to submit a block to a relay they don't have to send it seconds earlier to a block Builder we still has to simulate it and validate it and whatever right they can they also they know the position of everybody else's transactions in the block they can cancel their transactions they can make new transactions they can update them they can shuffle them around it basically gives them much greater control over their over how they execute their trading strategies and so I think if I had to guess then um these are my three kind of observations about the current market structure so Arbitrage is King uh sandwiches were disappear over time as kind of we get more better privacy Etc and and and uh and better dexes and then um statistical arbit charge will completely crowd out Atomic Arbitrage in any form of atomic trading and then block Builders and big trading firms I think this role will emerge and this is something that we've already seen yeah tons to dig into there um I agree with all of that and one thing that I I wanted to get at with you is this I I think that idea of the lag right this idea of warehousing risk even for a very tiny number of seconds is very key you know because before this season and started doing a bunch of research you kind of heard a lot about this idea of cross domain Meb sounds very exciting right but you know when you kind of dig in that's not really existing today and I my understanding is part of the reason outside of sex to Dex Arbitrage my understanding of the reason is if you look at like the block time for ethereum is 12 seconds if you look at something like polygon that block time is two seconds so even if you had an Arbitrage opened up right let's say you are three seconds into an ethereum Block in one second into a polygon block you could lock in the polygon side of that Arbitrage but then you still have nine seconds right on the ethereum Block and who's to say whether or not the validator executes on that second leg of the Arbitrage and the spreads are wider on both of those chains than something like a sex anyway so it's just not economical today to execute those arbitrages um although baby Suave fixes this in in some way um and you're going to school me half halfway through the season about why that might ultimately become possible but I think that's an important idea to concept to highlight and then the last thing that I wanted to get at I think you're getting another important point about latency and the importance of latency as well because these large sophisticated trading firms do not want to Warehouse risk for more you know they're not even operating on a second basis they're operating on a micro second basis than they need to and you you talked about Flash Boys before a little bit and we know in tradpy the role of latency is extremely important and that's starting to rear its head again in crypto so with that is kind of the context could you dig into like how do you think about latency what is the role that it plays both in the view of the mempool but then also in the strategy of these large sophisticated builders yeah the role of latency that's a very interesting one so from the perspective of the Searcher and the block beta I'm going to treat them here it's kind of the same bucket so the more time you have the more you can slow down time basically the more valuable the block that you can build for example if you can get more information about the word faster so if you can read the chain and any other quote-unquote chain so the external world you can read all of these prices and price movements and and whatnot and and everything that's going on the faster you can feed that into your model the more time you have to kind of compute and search that's where the name Searcher comes from the more you can search for optimal or like or profitable trades um that you can do against the real world right um and uh so and then of course you want to you want to maximize the efficiency of your algorithms itself So the faster you can run them the more you can parallelize and so on um the faster you can compute and search and then you also have the lack of getting uh whatever trades you want to make to the block Builder or if you're a block beta then to the relay through the relay to the proposal and so on and you would like to do that as late as possible because that again that maximizes your time and it minimizes the risk of something going wrong and that also hints to um this going wrong also hints to kind of the value of cancellations so you may submit your transaction but then the price moves rapidly and you kind of you say oh I don't actually want to make this trade anymore and so you have to cancel it and that happens all the time and so that shows you why many trading firms actually opt to become block Builders themselves because then any cancellation is instant because they're doing the competition and the block building locally they they don't have to go through around half the word to to some other block beta who has to well you know the the cancellation has to travel and they and then they have to execute it and then they have to send you back a receipt and whatnot read and so um yeah the more this has the models can be compressed of course the better for you and you can see why Searchers and Builders and proposers all have a very strong incentive to lower the latency between themselves as low as possible because that just maximizes their Collective payout and that's a very that's very very dangerous basically because um if this trend is or if if this incentive is is sort of allowed to run wild then what you get is at the limit you get Searchers who are co-located with block Builders and you get Block Builders who are co-located with validators all in a very small geographical area in the case of treadfy even within the same data center right inside um inside New Jersey or whatever right watch Chicago um and uh and and this might be okay in threadfy because threadfi is built on top of um local jurisdictions or local law law um and so on anyway but the ambition of crypto is that it's a system that is global and that is nutrient and when you have systems that rely on low latency where it's better to be if you have a lower latency towards other actors than to have a higher latency and so you can never completely avoid this but where it just pays a lot to have a low latency to other actors then you will always erode um this geographical decentralization and this neutrality over time because you basically disincentivize being somewhere in the world that's not close to everybody else and this is something that I predict um would be become a big up topic uh in the next year of talking about Mev and as usual day and um so Easter is the one of the co-founders of flashbots who wrote the original flashpoints 2.0 Paper that um that that first talked about Mev he recently put out a a post about latency and Geographic decentralization where he laid out this argument uh in much greater details so I would recommend everybody to to check that out because it's really important um what this means basically is that in the systems that we built we need to make sure that they are not sensitive to latency otherwise we would get this we would just recreate tread file we will recreate the same latency games and we will not we would basically fail in Building decentralized blockchain Systems instead we have to build systems that are more tolerant to to higher latency and who to actors who who have a higher latency and don't punish these actors for being at a different part of the world um because otherwise you will get what you wish for and that would be not good for crypto hmm I've got one one question for you here before we move on to our next topic here which is I totally I I generally agree um I agree with you on that front but I think also you know this this kind of hits into it there's Fierce debate right across where you would call kind of like the Mev maximalization corner of crypto and then the fair ordering uh order of uh corner of crypto and there's no sort of Shangri-La you know when it comes to this sort of thing so if you remove latency as a vector of competition for how Mev is extracted what is the other side of that coin if you had this steel man do you want me to Steven or do you want me to see him in the other side what I heard from that argument basically is like we we can't be up we can't allow uh latency to be the tradition the determining factor in how Mev gets extracted so what is the you know if you push down the latency competition Vector what is the other competition Vector that rises up so what competition Vector Rises up when you minimize latency is price and so because you turn you turn basically a latency auction into a into a price auction and you force the parties to compete on on who pays the most in order to fill a certain opportunity and price is more compatible with geographical decentralization than latency and so that is one big reason um there are other reasons as well so auctions are generally more fair and more welfare maximizing um and they also uh with a maximizing meaning so the the party wants the item the most I'm more likely to get it and then they are also more efficient in the sense that they maximize revenue for the seller of block space and so in in in a market where the the value data or the sequencer can pick their own ordering then they would always prefer to do an auction because that actually maximizes the revenue that they can get I would assume and this may be where we build a bridge to the modular stack again so I can totally understand the appeal of um a fair ordering protocols um they just feel more fair they are it's sort of very natural that as a human you you think well I was like my transaction should be ordered in the order that it was received right and um it's only at the limit that it starts to break down um when Searchers start to compete and basically leads to this geographical decentralization but that's the same argument as why users love Robin Hood it's basically the good is very visible that the bad it's very invisible to them it's a kind of systemic effect that doesn't affect them personally it only affects the guarantees of the system as a whole but that said there are some nice properties that filtering protocols have that that options don't have and I would say the biggest one the biggest one is it's much easier to make a fair ordering protocol private than to make an auction private so if you have a list of encrypted transactions then you can only reveal um the timestamp when the transaction was received and you can come to consensus on that in a decentralized network um and and then you can order these transactions and you can later decrypt them and then you have your ordering but it is a much harder problem to take the same list of encrypted transactions and compute the output of an efficient auction where you say the transaction that pays the most goes at the top but you also want to minimize any conflicts between them right because in in this type of system a lot of transactions were basically conflict with each other right and so this is true in both cases but at the limit it's it is easier to to make a fail during Protocol private than it is to make an auction private and so that's my personal Steel Man of fair uh ordering protocols I think it'll be interesting to see because you know we've got the two maybe biggest brand kind of layer twos on ethereum have very different approaches to Mev between optimism and arbitrum so it'll be fun to see how that kind of plays out in practice um yeah in stock net I don't think has commented at all yet right on on what kind of uh ordering Preference they would prefer at least that I'm aware of no no me either um and I mean this decision will be made I think in real time there's going to be I mean we're recording this on the day I think ZK Sync has gone live so congratulations but you know there's a polygon is launching their their ZK Network as well so I think this this decision will be made in real time we'll probably see the pros and cons play out and it'll be very interesting um one other uh so a lot of this season is going to be focused on Mev on ethereum but we also have a couple episodes dedicated we've got a Meb on Solana episode and an Mev on Cosmos episode uh now this is the cosmos one's a little near and dear to my heart we the whole last season was pretty much focused on Cosmos and we did an MVB episode but you know I'd be curious you know as someone who's spent a lot of time like very close to the metal or kind of in the guts of ethereum you know consensus and how Meb Dynamics are playing out on ethereum I'd be curious you know what you're interested in or kind of hoping to get out of the Solana and Cosmos episodes yeah for Solana I think um if I'm not totally mistaken I think in many ways it it can be a case study for why you shouldn't build low latency blockchains um um so it's I I kind I see it almost more as as an anti-example in that sense so um it I think we will talk about the centralizing effect of of low latency and what this does to a valid asset and what this does to vertical integration between um block Builders and uh and validate us um and it's maybe not a surprise I think that the block Builder said if I'm not totally mistaken at least one of two block builders on Solana so I saw um operating a liquid sticking protocol um because just by running um the extra validators and the Builder in the same place they just have a big and the big big advantage over others right then I think we will talk about uh well free market design which is I mean that's tangentially related to Mev I guess but it shows that if you don't have a robust um mempool and fee Market design and um then you get uh basically a lot of spam a lot of failed transactions I saw an example uh the other day that 50 or more of Solana transactions actually failed Arbitrage transactions which is so insane if you think about it 58 yeah and then for Cosmos I think Cosmos and Mev is super fun I I listened to all of the episodes that that you did on Mev and Cosmos I know most of the people I'm an investor in um osmosis uh because I think they are doing something very interesting um I know the guys from skip very well I think their approach to on-chain block building and onshine searching I think that's something new that we haven't seen before and then um I think there's a Noma and penumbra to uh two projects that are at least kind of intellectually quite close to suave in the sense that they have this so they both have privacy as a big part of their project and they have this they want to move users from making regular executable transactions to having kind of intent based uh transaction framework and this is something that we also think a lot about and that I am personally very bullish on and so I'm I am really looking forward to picking these guys minds and yeah diving into some of the unique Mev ideas they have over in Cosmos me as well yeah it you know it was funny to to hear miles laid out in that season uh an articulation of the perfect Mev solution with two of which are gonna seem they apply perfectly to ethereum but one is different and one is the three prongs of a perfect mbb solution from his perspective was one avoid centralization at the validator level check for ethereum uh minimizes harmful forms of Meb like sandwiches I think check for ethereum but then the third prong is this is a little bit uh osmosis specific which is you have a way to return Mev to the protocol so osmosis has a proto-ref module right which is a pretty exciting experiment I think there is a difference in ethereum which is uh returning of Mev to the user um so it's there's you know the cool thing about Cosmos that I love doing that season is you know it's very each they're very different opinions there and they kind of think about the world in a different way and like osmosis has a very opinionated approach to Emmy fee and because they're their own Sovereign chain they can do that and it doesn't necessarily perfectly align with the rest of the cosmos ecosystem which is just cool it's a diversity of ideas and opinions yeah and I'm I think something that we should dig into when we talk to them is how much of this how how much of the opinionated nature can they retain when they actually start Outsourcing um their security needs right because the big drawback in uh in Cosmos right now is all of these chains have their own Val data sets and um so they have this idea of mesh security and they have this idea of uh The Interchange security that you can you can Outsource your sequencing to to the cosmos Hub and as that catches on how can they keep their own uh ordering and mempool policies while also getting the security from another blockchain I think is there a compromise there that would be very interesting for me to know I agree I agree um so the last topic that I want to get your opinion on and frankly this is one that we might not have an answer to but is is this is the idea of Regulation so right now kind of the big theme in crypto is regulation finally colliding with our sector in a big way especially within the context of the United States right the SEC has taken a very sort of opinionated stance and approach and there's probably it's only a matter of time bless you before that comes to Mev as well and you know it has struck me that sometimes we talk about Mev as this like hey we are as a community need to make a decision about the way that this should work but the United States and our regulatory apparatus has its own opinion right about how value you know should be trans uh you know transmitted in financial systems and a very specific definition of what best execution means for instance and you know to put my own opinion forth here I think a situation where users are front run or sandwiched but some amount of Mev is passed back to them would not fit that you know their specific definition of best execution today so let me just pose that to you it's first of all do you agree with that statement and second of all what how do you think regulation kind of bumps into Mev I think that's a great question and we have to caveat this I mean it's always speculation right yes um I think I think if you zoom out far enough then U.S financial regulation and crypto or at least the consumer protection part of it is actually very very aligned because um what crypto at the end of the day is all about is creating more fair and Equitable markets for users where there are fewer Central parties who can exploit them in some shape or form and you sometimes have to make compromises in the short to medium term saw our systems today they fall short of that and not just because the system is poorly designed it's more so that the applications on top of it are poorly designed and this in turn may be kind of this may be a result of like lack of privacy lack of throughput Etc right um but uh I think the Silver Lining is that you know the execution that users can get on public blockchains is getting better and better every year so if you if you just compare um kind of the execution quality of users I would love to see that charted on a graph and I think it's it's going up you know parabolically and I think it'll continue to go up as we learn to build better exchanges and as we learn to make the the base layer more imv resistant Etc nonetheless so I would also agree that yes sort of the crypto does not currently fit into any Frameworks of uh what best execution means in traditional Finance I think that's okay I think that um definitions can change and I also think Regulators are pragmatic and use a kind of I think they apply their Force where it's the most necessary except if they get some kind of of course orders from above that are more politically or of kind of National Security interest um and the the third point would be that what we need to build our systems in a way that they are just not subject to the regulation of a single party because of a single regulatory regime can make the rules in crypto then crypto just as a concept has just failed and that's why I'm so anti-latency minimization and so on as well because this just creates the conditions for crypto to centralize in a single geographical regime and this is something that we have to avoid we need to make it so that that crypto has power sent us in the US in Europe in Africa in Asia in China and so on and I think that's when crypto research reaches its its maximum resilience and the and not single regulator can come along and kind of enforce its own preferences or utility function on the system as a whole they maybe they can say well as a U.S validator here's what you can and can do right but this will only have a small effect on the system as a whole because the other value that I might still do what they want right and so I think in order to build a system that is truly robust then you you just need participants from many jurisdictions and you need a way for their own utility functions to kind of make it into this hot pot of utility functions that that creates the the total guarantees of the system and I think you know I think the fair caveat to say a sum of the subject matter that we cover in this season is going to be discussing what's currently happen happening but some of it is necessarily going to be speculating a little bit about how things are going to play out in the future um and so we'll do our best to caveat when that's the case but um I think we covered all the major topics that we're going to be getting into I think this is going to be especially if you're a nerd around Mev or how blockchain systems work this is going to be a wildly fun season so yeah I'm really looking forward to to dig into it and we've got a great first episode lined up with Justin and and tarun so we'll we'll dig into it more then yeah so it's great I look forward to that episode as well all right my friend I'll talk to you soon foreign [Music]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Youtube video\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 152,\n        \"samples\": [\n          \"The Staking Router + DVT: A Seismic Change for LSTs | Izzy (Lido) & Ois\\u00edn (Obol)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publish_Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 151,\n        \"samples\": [\n          \"2023-06-09 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Video_Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1041.6561899136204,\n        \"min\": 617.0,\n        \"max\": 7312.0,\n        \"num_unique_values\": 151,\n        \"samples\": [\n          4338.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Bell Curve\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fb30fb06-f59b-4e8b-8f85-2b4da7233664\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VideoId</th>\n",
              "      <th>URL</th>\n",
              "      <th>Transcript</th>\n",
              "      <th>Type</th>\n",
              "      <th>Title</th>\n",
              "      <th>Publish_Date</th>\n",
              "      <th>Video_Length</th>\n",
              "      <th>Author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YpsB6wNZ5jc</td>\n",
              "      <td>https://www.youtube.com/watch?v=YpsB6wNZ5jc</td>\n",
              "      <td>hey everyone wanted to give a quick shout out ...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Will Crypto Leave the US? | Roundup</td>\n",
              "      <td>2024-05-10 00:00:00</td>\n",
              "      <td>4023.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NgGi4-gykEc</td>\n",
              "      <td>https://www.youtube.com/watch?v=NgGi4-gykEc</td>\n",
              "      <td>normal contributors have been working with tal...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Interoperability's Product-Market Fit | Deep Dive</td>\n",
              "      <td>2024-05-08 00:00:00</td>\n",
              "      <td>3054.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WjQHMTASy-4</td>\n",
              "      <td>https://www.youtube.com/watch?v=WjQHMTASy-4</td>\n",
              "      <td>I feel it was super positive and bullish for A...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Eigen's Dual Staking Dilemma: Eth vs Eigen Sec...</td>\n",
              "      <td>2024-05-03 00:00:00</td>\n",
              "      <td>4588.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iFFfb24_Be0</td>\n",
              "      <td>https://www.youtube.com/watch?v=iFFfb24_Be0</td>\n",
              "      <td>the way that I view what's been happening in c...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Crypto's Multichain Masterplan | S7 E8</td>\n",
              "      <td>2024-04-24 00:00:00</td>\n",
              "      <td>5552.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SrZz6WlnUt8</td>\n",
              "      <td>https://www.youtube.com/watch?v=SrZz6WlnUt8</td>\n",
              "      <td>I think there's an ending point to each protoc...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Bitcoin's Renaissance: Inside Runes, Ordinals,...</td>\n",
              "      <td>2024-04-19 00:00:00</td>\n",
              "      <td>4182.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>pKMJwPtjFVs</td>\n",
              "      <td>https://www.youtube.com/watch?v=pKMJwPtjFVs</td>\n",
              "      <td>do you have tom brady like jump through a hoop...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>Merge Chaos, Coinbase’s Proposal &amp; On-Chain IP...</td>\n",
              "      <td>2022-09-09 00:00:00</td>\n",
              "      <td>4640.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>xMkndDY8sWQ</td>\n",
              "      <td>https://www.youtube.com/watch?v=xMkndDY8sWQ</td>\n",
              "      <td>the average users and the average borrower dol...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>The Makings of a DeFi Credit Boom | Tushar Jain</td>\n",
              "      <td>2022-09-06 00:00:00</td>\n",
              "      <td>3709.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>yXKKnulowIc</td>\n",
              "      <td>https://www.youtube.com/watch?v=yXKKnulowIc</td>\n",
              "      <td>like if we're all just investing in picks and ...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>L1 Death Race, L2 Summer &amp; Maker’s End Game | ...</td>\n",
              "      <td>2022-09-02 00:00:00</td>\n",
              "      <td>4589.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>R2kpUU0WsQQ</td>\n",
              "      <td>https://www.youtube.com/watch?v=R2kpUU0WsQQ</td>\n",
              "      <td>[Music] all right new season new show episode ...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>The DeFi Credit Boom | Season One Pilot</td>\n",
              "      <td>2022-08-30 00:00:00</td>\n",
              "      <td>617.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>HURlq6rIEEw</td>\n",
              "      <td>https://www.youtube.com/watch?v=HURlq6rIEEw</td>\n",
              "      <td>eventually you're just going to move to where ...</td>\n",
              "      <td>Youtube video</td>\n",
              "      <td>CeFi Is Dead, Long Live DeFi | Vance Spencer &amp;...</td>\n",
              "      <td>2022-08-30 00:00:00</td>\n",
              "      <td>4317.0</td>\n",
              "      <td>Bell Curve</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb30fb06-f59b-4e8b-8f85-2b4da7233664')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb30fb06-f59b-4e8b-8f85-2b4da7233664 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb30fb06-f59b-4e8b-8f85-2b4da7233664');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fba64ca-2ee5-4ef2-b237-2a15503ec9ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fba64ca-2ee5-4ef2-b237-2a15503ec9ec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fba64ca-2ee5-4ef2-b237-2a15503ec9ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_15893489-22a3-4b35-930f-8e1ff3d2f142\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_15893489-22a3-4b35-930f-8e1ff3d2f142 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         VideoId                                          URL  \\\n",
              "0    YpsB6wNZ5jc  https://www.youtube.com/watch?v=YpsB6wNZ5jc   \n",
              "1    NgGi4-gykEc  https://www.youtube.com/watch?v=NgGi4-gykEc   \n",
              "2    WjQHMTASy-4  https://www.youtube.com/watch?v=WjQHMTASy-4   \n",
              "3    iFFfb24_Be0  https://www.youtube.com/watch?v=iFFfb24_Be0   \n",
              "4    SrZz6WlnUt8  https://www.youtube.com/watch?v=SrZz6WlnUt8   \n",
              "..           ...                                          ...   \n",
              "147  pKMJwPtjFVs  https://www.youtube.com/watch?v=pKMJwPtjFVs   \n",
              "148  xMkndDY8sWQ  https://www.youtube.com/watch?v=xMkndDY8sWQ   \n",
              "149  yXKKnulowIc  https://www.youtube.com/watch?v=yXKKnulowIc   \n",
              "150  R2kpUU0WsQQ  https://www.youtube.com/watch?v=R2kpUU0WsQQ   \n",
              "151  HURlq6rIEEw  https://www.youtube.com/watch?v=HURlq6rIEEw   \n",
              "\n",
              "                                            Transcript           Type  \\\n",
              "0    hey everyone wanted to give a quick shout out ...  Youtube video   \n",
              "1    normal contributors have been working with tal...  Youtube video   \n",
              "2    I feel it was super positive and bullish for A...  Youtube video   \n",
              "3    the way that I view what's been happening in c...  Youtube video   \n",
              "4    I think there's an ending point to each protoc...  Youtube video   \n",
              "..                                                 ...            ...   \n",
              "147  do you have tom brady like jump through a hoop...  Youtube video   \n",
              "148  the average users and the average borrower dol...  Youtube video   \n",
              "149  like if we're all just investing in picks and ...  Youtube video   \n",
              "150  [Music] all right new season new show episode ...  Youtube video   \n",
              "151  eventually you're just going to move to where ...  Youtube video   \n",
              "\n",
              "                                                 Title         Publish_Date  \\\n",
              "0                  Will Crypto Leave the US? | Roundup  2024-05-10 00:00:00   \n",
              "1    Interoperability's Product-Market Fit | Deep Dive  2024-05-08 00:00:00   \n",
              "2    Eigen's Dual Staking Dilemma: Eth vs Eigen Sec...  2024-05-03 00:00:00   \n",
              "3               Crypto's Multichain Masterplan | S7 E8  2024-04-24 00:00:00   \n",
              "4    Bitcoin's Renaissance: Inside Runes, Ordinals,...  2024-04-19 00:00:00   \n",
              "..                                                 ...                  ...   \n",
              "147  Merge Chaos, Coinbase’s Proposal & On-Chain IP...  2022-09-09 00:00:00   \n",
              "148    The Makings of a DeFi Credit Boom | Tushar Jain  2022-09-06 00:00:00   \n",
              "149  L1 Death Race, L2 Summer & Maker’s End Game | ...  2022-09-02 00:00:00   \n",
              "150            The DeFi Credit Boom | Season One Pilot  2022-08-30 00:00:00   \n",
              "151  CeFi Is Dead, Long Live DeFi | Vance Spencer &...  2022-08-30 00:00:00   \n",
              "\n",
              "     Video_Length      Author  \n",
              "0          4023.0  Bell Curve  \n",
              "1          3054.0  Bell Curve  \n",
              "2          4588.0  Bell Curve  \n",
              "3          5552.0  Bell Curve  \n",
              "4          4182.0  Bell Curve  \n",
              "..            ...         ...  \n",
              "147        4640.0  Bell Curve  \n",
              "148        3709.0  Bell Curve  \n",
              "149        4589.0  Bell Curve  \n",
              "150         617.0  Bell Curve  \n",
              "151        4317.0  Bell Curve  \n",
              "\n",
              "[152 rows x 8 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LTmc88QSOJyZ"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('Bell_curve_latest.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZIhM4y0KOjpd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Bell_curve_latest.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/152 [00:00<?, ?it/s]/home/bilal326/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            " 10%|▉         | 15/152 [12:52<1:57:31, 51.47s/it]\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/claude/reference/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m video_url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract summary and metadata\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mextract_summary_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_url\u001b[49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m#######################################################################################################\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# output, metadata = extract_summary_and_metadata(video_url)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m detailed_summary \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m##################################################################################################################\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mextract_summary_and_metadata\u001b[0;34m(video_url)\u001b[0m\n\u001b[1;32m     44\u001b[0m refine_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(refine_template)\n\u001b[1;32m     45\u001b[0m chain \u001b[38;5;241m=\u001b[39m load_summarize_chain(\n\u001b[1;32m     46\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     47\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     )\n\u001b[0;32m---> 55\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m detailed_summary \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/combine_documents/refine.py:157\u001b[0m, in \u001b[0;36mRefineDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     base_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_refine_inputs(doc, res)\n\u001b[1;32m    156\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 157\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine_llm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     refine_steps\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(refine_steps, res)\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/llm.py:316\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:560\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    554\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    558\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    559\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:421\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    420\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 421\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    422\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    423\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    425\u001b[0m ]\n\u001b[1;32m    426\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:411\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 411\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:632\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/langchain_anthropic/chat_models.py:514\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_output(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/resources/messages.py:681\u001b[0m, in \u001b[0;36mMessages.create\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m600\u001b[39m,\n\u001b[1;32m    680\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message \u001b[38;5;241m|\u001b[39m Stream[MessageStreamEvent]:\n\u001b[0;32m--> 681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1004\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1003\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1052\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1004\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1003\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1052\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/rag_project2/rag_project/my_virtual_env/lib/python3.10/site-packages/anthropic/_base_client.py:1019\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1018\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1019\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1022\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1023\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1027\u001b[0m )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/claude/reference/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}"
          ]
        }
      ],
      "source": [
        "api_key = \"AIzaSyCIVHAyo1QU194HManplOS0JZteERJyvvY\"\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "def extract_summary_and_metadata(video_url):\n",
        "    loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=True)\n",
        "    result = loader.load()\n",
        "    \n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=25000, chunk_overlap=500)\n",
        "    texts = text_splitter.split_documents(result)\n",
        "\n",
        "    # Assuming the defined classes and functions in your code snippet\n",
        "    llm = ChatAnthropic(temperature=0, max_tokens=4000, model_name=\"claude-3-haiku-20240307\", anthropic_api_key=\"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\")\n",
        "    # llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", api_key = openai_api_key, temperature=0, max_tokens=4000)\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    <Task>\n",
        "    Generate a highly detailed summary of a YouTube video transcript focused on analysis of cryptocurrencies.\n",
        "    </Task>\n",
        "    <Inputs>\n",
        "    {text}\n",
        "    </Inputs>\n",
        "    <Instructions>\n",
        "    Write a very detailed summary of a youtube video transcript. Below are the instructions:\n",
        "    - Read the provided YouTube video transcript thoroughly.\n",
        "    - Extract any financial advice, technical analysis, predictions, crypto currencies and other entities mentioned in the transcript, along with the reasoning, arguments and claims behind it.\n",
        "    - Assess the overall sentiment of the transcript and determine whether it is bullish or bearish.\n",
        "    - In the end give a one line summary of the transcript highlighting the main message and conclusion\n",
        "    - Give the output without any introductory lines or context statements. Do not use the word transcript or summary in the output. Simply begin the output with the summary itself.\"\n",
        "    </Instructions>\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    refine_template = (\n",
        "        \"Your task is to produce an enhanced and more comprehensive summary.\\n\"\n",
        "        \"The existing summary is: {existing_answer}\\n\"\n",
        "        \"You should maintain the overall structure and flow of the existing summary, but expand upon it by incorporating additional relevant details and insights from the provided context.\\n\"\n",
        "        \"Do not use the word refined, transcript, or summary in the output. Simply begin the output with the refined summary itself\\n\"\n",
        "        \"----------\\n\"\n",
        "        \"{text}\\n\"\n",
        "        \"----------\\n\"\n",
        "        \"Using the new context, refine and enrich the existing detailed summary. If the additional context does not offer any useful information to expand the summary, simply return the original summary as is.\"\n",
        "        )\n",
        "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "    chain = load_summarize_chain(\n",
        "        llm=llm,\n",
        "        chain_type=\"refine\",\n",
        "        question_prompt=prompt,\n",
        "        refine_prompt=refine_prompt,\n",
        "        return_intermediate_steps=True,\n",
        "        input_key=\"input_documents\",\n",
        "        output_key=\"output_text\",\n",
        "        verbose=False\n",
        "        )\n",
        "    result = chain({\"input_documents\": texts}, return_only_outputs=True)\n",
        "\n",
        "    detailed_summary = result['output_text']\n",
        "\n",
        "    return result\n",
        "\n",
        "##############################################################################################\n",
        "##############################################################################################\n",
        "    # return result, metadata\n",
        "\n",
        "data = df.copy()\n",
        "# subset_latest_videos = subset_latest_videos[1:]\n",
        "\n",
        "data['Detailed_Summary'] = \"\"\n",
        "\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in tqdm(data.iterrows(), total=len(data)):\n",
        "    video_url = row['URL']\n",
        "\n",
        "    # Extract summary and metadata\n",
        "    output = extract_summary_and_metadata(video_url)             #######################################################################################################\n",
        "    # output, metadata = extract_summary_and_metadata(video_url)\n",
        "    detailed_summary = output['output_text'] ##################################################################################################################\n",
        "    # one_line_summary = output2.content[0].text ##################################################################################################################\n",
        "    # Update DataFrame with summary and metadata\n",
        "    data.at[index, 'Detailed_Summary'] = detailed_summary\n",
        "\n",
        "\n",
        "    # Delay of 60 seconds\n",
        "    time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
